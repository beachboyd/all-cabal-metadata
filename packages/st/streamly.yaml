homepage: https://github.com/composewell/streamly
changelog-type: markdown
hash: 2a510275b3a41f1e50d8f45f8dac879933139652509dd6cd98b69a5d24e9c55d
test-bench-deps:
  exceptions: ! '>=0.8 && <0.11'
  base: ! '>=4.8 && <5'
  hspec: ! '>=2.0 && <3'
  gauge: ! '>=0.2.4 && <0.3'
  containers: ! '>=0.5.8.2 && <0.7'
  mtl: ! '>=2.2 && <3'
  transformers: ! '>=0.4 && <0.6'
  random: ! '>=1.0.0 && <2'
  deepseq: ! '>=1.4.1 && <1.5'
  QuickCheck: ! '>=2.10 && <2.14'
  streamly: -any
maintainer: streamly@composewell.com
synopsis: Beautiful Streaming, Concurrent and Reactive Composition
changelog: |
  ## 0.7.0

  ### Breaking changes

  * Change the signature of `foldrM` to ensure that it is lazy
  * Change the signature of `iterateM` to ensure that it is lazy.
  * `scanx` would now require an additional `Monad m` constraint.

  ### Behavior change

  * Earlier `ParallelT` was unaffected by `maxBuffer` directive, now `maxBuffer`
    can limit the buffer of a `ParallelT` stream as well. When the buffer becomes
    full, the producer threads block.
  * `ParallelT` streams no longer have an unlimited buffer by default. Now the
    buffer for parallel streams is limited to 1500 by default, the same as other
    concurrent stream types.

  ### Deprecations

  * In `Streamly.Prelude`:
      * `runStream` has been replaced by `drain`
      * `runN` has been replaced by `drainN`
      * `runWhile` has been replaced by `drainWhile`
      * `fromHandle` has been deprecated. Please use
        `Streamly.FileSystem.Handle.read`, `Streamly.Data.Unicode.Stream.decodeUtf8` and
        `splitOnSuffix` with `Streamly.Data.Fold.toList` to split the
         stream to a stream of `String` separated by a newline.
      * `toHandle` has been deprecated. Please use `intersperse` and `concatUnfold` to
        add newlines to a stream, `Streamly.Data.Unicode.Stream.encodeUtf8` for encoding and
        `Streamly.FileSystem.Handle.write` for writing to a file handle.
      * Deprecate `scanx`, `foldx`, `foldxM`, `foldr1`
      * Remove deprecated APIs `foldl`, `foldlM`
      * Replace deprecated API `scan` with a new signature, to scan using Fold.

  * In `Streamly` module:
      * `runStream` has been deprecated, please use `Streamly.Prelude.drain`

  * Remove deprecated module `Streamly.Time` (moved to Streamly.Internal.Data.Time)
  * Remove module `Streamly.Internal` (functionality moved to the Internal hierarchy)

  ### Bug Fixes

  * Fix a bug that caused `uniq` function to yield the same element twice.
  * Fix a bug that caused "thread blocked indefinitely in an MVar operation"
    exception in a parallel stream.

  ### Major Enhancements

  This release contains a lot of new features and major enhancements.  For more
  details on the new features described below please see the haddock docs of the
  modules on hackage.

  #### Exception Handling

  See `Streamly.Prelude` for new exception handling combinators like `before`,
  `after`, `bracket`, `onException`, `finally`, `handle` etc.

  #### Composable Folds

  `Streamly.Data.Fold` module provides composable folds (stream consumers). Folds
  allow splitting, grouping, partitioning, unzipping and nesting a stream onto
  multiple folds without breaking the stream. Combinators are provided for
  temporal and spatial window based fold operations, for example, to support
  folding and aggregating data for timeout or inactivity based sessions.

  #### Composable Unfolds

  `Streamly.Data.Unfold` module provides composable stream generators. Unfolds allow
  high performance merging/flattening/combining of stream generators.

  #### Streaming File IO

  `Streamly.FileSystem.Handle` provides handle based streaming file IO
  operations.

  #### Streaming Network IO

  * `Streamly.Network.Socket` provides socket based streaming network IO
  operations.

  * `Streamly.Network.Inet.TCP` provides combinators to build Inet/TCP
  clients and servers.

  #### Concurrent concatMap

  The new `concatMapWith` in `Streamly.Prelude` combinator performs a
  `concatMap` using a supplied merge/concat strategy. This is a very
  powerful combinator as you can, for example, concat streams
  concurrently using this.

  ### Other Enhancements

  * Add the following new features/modules:
    * _Unicode Strings_: `Streamly.Data.Unicode.Stream` module provides
      encoding/decoding of character streams and other character stream
      operations.
    * _Arrays_: `Streamly.Memory.Array` module provides arrays for efficient
      in-memory buffering and efficient interfacing with IO.

  * Add the following to `Streamly.Prelude`:
      * `unfold`, `fold`, `scan` and `postscan`
      * `concatUnfold` to concat a stream after unfolding each element
      * `intervalsOf` and `chunksOf`
      * `splitOn`, `splitOnSuffix`, `splitWithSuffix`, and `wordsBy`
      * `groups`, `groupsBy` and `groupsByRolling`
      * `postscanl'` and `postscanlM'`
      * `intersperse` intersperse an element in between consecutive elements in
        stream
      * `trace` combinator maps a monadic function on a stream just for side
        effects
      * `tap` redirects a copy of the stream to a `Fold`

  ## 0.6.1

  ### Bug Fixes

  * Fix a bug that caused `maxThreads` directive to be ignored when rate control
    was not used.

  ### Enhancements

  * Add GHCJS support
  * Remove dependency on "clock" package

  ## 0.6.0

  ### Breaking changes

  * `Monad` constraint may be needed on some of the existing APIs (`findIndices`
    and `elemIndices`).

  ### Enhancements

  * Add the following functions to Streamly.Prelude:
      * Generation: `replicate`, `fromIndices`, `fromIndicesM`
      * Enumeration: `Enumerable` type class, `enumerateFrom`, `enumerateFromTo`,
        `enumerateFromThen`, `enumerateFromThenTo`, `enumerate`, `enumerateTo`
      * Running: `runN`, `runWhile`
      * Folds: `(!!)`, `maximumBy`, `minimumBy`, `the`
      * Scans: `scanl1'`, `scanl1M'
      * Filters: `uniq`, `insertBy`, `deleteBy`, `findM`
      * Multi-stream: `eqBy`, `cmpBy`, `mergeBy`, `mergeByM`, `mergeAsyncBy`,
        `mergeAsyncByM`, `isPrefixOf`, `isSubsequenceOf`, `stripPrefix`,
        `concatMap`, `concatMapM`, `indexed`, `indexedR`
  * Following instances were added for `SerialT m`, `WSerialT m` and
    `ZipSerialM m`:
    * When `m` ~ `Identity`: IsList, Eq, Ord, Show, Read, IsString, NFData,
      NFData1, Traversable
    * When `m` is `Foldable`: Foldable
  * Performance improvements
  * Add benchmarks to measure composed and iterated operations

  ## 0.5.2

  ### Bug Fixes

  * Cleanup any pending threads when an exception occurs.
  * Fixed a livelock in ahead style streams. The problem manifests sometimes when
    multiple streams are merged together in ahead style and one of them is a nil
    stream.
  * As per expected concurrency semantics each forked concurrent task must run
    with the monadic state captured at the fork point.  This release fixes a bug,
    which, in some cases caused an incorrect monadic state to be used for a
    concurrent action, leading to unexpected behavior when concurrent streams are
    used in a stateful monad e.g. `StateT`. Particularly, this bug cannot affect
    `ReaderT`.

  ## 0.5.1

  * Performance improvements, especially space consumption, for concurrent
    streams

  ## 0.5.0

  ### Bug Fixes

  * Leftover threads are now cleaned up as soon as the consumer is garbage
    collected.
  * Fix a bug in concurrent function application that in certain cases would
    unnecessarily share the concurrency state resulting in incorrect output
    stream.
  * Fix passing of state across `parallel`, `async`, `wAsync`, `ahead`, `serial`,
    `wSerial` combinators. Without this fix combinators that rely on state
    passing e.g.  `maxThreads` and `maxBuffer` won't work across these
    combinators.

  ### Enhancements

  * Added rate limiting combinators `rate`, `avgRate`, `minRate`, `maxRate` and
    `constRate` to control the yield rate of a stream.
  * Add `foldl1'`, `foldr1`, `intersperseM`, `find`, `lookup`, `and`, `or`,
    `findIndices`, `findIndex`, `elemIndices`, `elemIndex`, `init` to Prelude

  ### Deprecations

  * The `Streamly.Time` module is now deprecated, its functionality is subsumed
    by the new rate limiting combinators.

  ## 0.4.1

  ### Bug Fixes

  * foldxM was not fully strict, fixed.

  ## 0.4.0

  ### Breaking changes

  * Signatures of `zipWithM` and `zipAsyncWithM` have changed
  * Some functions in prelude now require an additional `Monad` constraint on
    the underlying type of the stream.

  ### Deprecations

  * `once` has been deprecated and renamed to `yieldM`

  ### Enhancements

  * Add concurrency control primitives `maxThreads` and `maxBuffer`.
  * Concurrency of a stream with bounded concurrency when used with `take` is now
    limited by the number of elements demanded by `take`.
  * Significant performance improvements utilizing stream fusion optimizations.
  * Add `yield` to construct a singleton stream from a pure value
  * Add `repeat` to generate an infinite stream by repeating a pure value
  * Add `fromList` and `fromListM` to generate streams from lists, faster than
    `fromFoldable` and `fromFoldableM`
  * Add `map` as a synonym of fmap
  * Add `scanlM'`, the monadic version of scanl'
  * Add `takeWhileM` and `dropWhileM`
  * Add `filterM`

  ## 0.3.0

  ### Breaking changes

  * Some prelude functions, to whom concurrency capability has been added, will
    now require a `MonadAsync` constraint.

  ### Bug Fixes

  * Fixed a race due to which, in a rare case, we might block indefinitely on
    an MVar due to a lost wakeup.
  * Fixed an issue in adaptive concurrency. The issue caused us to stop creating
    more worker threads in some cases due to a race. This bug would not cause any
    functional issue but may reduce concurrency in some cases.

  ### Enhancements
  * Added a concurrent lookahead stream type `Ahead`
  * Added `fromFoldableM` API that creates a stream from a container of monadic
    actions
  * Monadic stream generation functions `consM`, `|:`, `unfoldrM`, `replicateM`,
    `repeatM`, `iterateM` and `fromFoldableM` can now generate streams
    concurrently when used with concurrent stream types.
  * Monad transformation functions `mapM` and `sequence` can now map actions
    concurrently when used at appropriate stream types.
  * Added concurrent function application operators to run stages of a
    stream processing function application pipeline concurrently.
  * Added `mapMaybe` and `mapMaybeM`.

  ## 0.2.1

  ### Bug Fixes
  * Fixed a bug that caused some transformation ops to return incorrect results
    when used with concurrent streams. The affected ops are `take`, `filter`,
    `takeWhile`, `drop`, `dropWhile`, and `reverse`.

  ## 0.2.0

  ### Breaking changes
  * Changed the semantics of the Semigroup instance for `InterleavedT`, `AsyncT`
    and `ParallelT`. The new semantics are as follows:
    * For `InterleavedT`, `<>` operation interleaves two streams
    * For `AsyncT`, `<>` now concurrently merges two streams in a left biased
      manner using demand based concurrency.
    * For `ParallelT`, the `<>` operation now concurrently meges the two streams
      in a fairly parallel manner.

    To adapt to the new changes, replace `<>` with `serial` wherever it is used
    for stream types other than `StreamT`.

  * Remove the `Alternative` instance.  To adapt to this change replace any usage
    of `<|>` with `parallel` and `empty` with `nil`.
  * Stream type now defaults to the `SerialT` type unless explicitly specified
    using a type combinator or a monomorphic type.  This change reduces puzzling
    type errors for beginners. It includes the following two changes:
    * Change the type of all stream elimination functions to use `SerialT`
      instead of a polymorphic type. This makes sure that the stream type is
      always fixed at all exits.
    * Change the type combinators (e.g. `parallely`) to only fix the argument
      stream type and the output stream type remains polymorphic.

    Stream types may have to be changed or type combinators may have to be added
    or removed to adapt to this change.
  * Change the type of `foldrM` to make it consistent with `foldrM` in base.
  * `async` is renamed to `mkAsync` and `async` is now a new API with a different
    meaning.
  * `ZipAsync` is renamed to `ZipAsyncM` and `ZipAsync` is now ZipAsyncM
    specialized to the IO Monad.
  * Remove the `MonadError` instance as it was not working correctly for
    parallel compositions. Use `MonadThrow` instead for error propagation.
  * Remove Num/Fractional/Floating instances as they are not very useful. Use
    `fmap` and `liftA2` instead.

  ### Deprecations
  * Deprecate and rename the following symbols:
      * `Streaming` to `IsStream`
      * `runStreaming` to `runStream`
      * `StreamT` to `SerialT`
      * `InterleavedT` to `WSerialT`
      * `ZipStream` to `ZipSerialM`
      * `ZipAsync` to `ZipAsyncM`
      * `interleaving` to `wSerially`
      * `zipping` to `zipSerially`
      * `zippingAsync` to `zipAsyncly`
      * `<=>` to `wSerial`
      * `<|` to `async`
      * `each` to `fromFoldable`
      * `scan` to `scanx`
      * `foldl` to `foldx`
      * `foldlM` to `foldxM`
  * Deprecate the following symbols for future removal:
      * `runStreamT`
      * `runInterleavedT`
      * `runAsyncT`
      * `runParallelT`
      * `runZipStream`
      * `runZipAsync`

  ### Enhancements
  * Add the following functions:
      * `consM` and `|:` operator to construct streams from monadic actions
      * `once` to create a singleton stream from a monadic action
      * `repeatM` to construct a stream by repeating a monadic action
      * `scanl'` strict left scan
      * `foldl'` strict left fold
      * `foldlM'` strict left fold with a monadic fold function
      * `serial` run two streams serially one after the other
      * `async` run two streams asynchronously
      * `parallel` run two streams in parallel (replaces `<|>`)
      * `WAsyncT` stream type for BFS version of `AsyncT` composition
  * Add simpler stream types that are specialized to the IO monad
  * Put a bound (1500) on the output buffer used for asynchronous tasks
  * Put a limit (1500) on the number of threads used for Async and WAsync types

  ## 0.1.2

  ### Enhancements
  * Add `iterate`, `iterateM` stream operations

  ### Bug Fixes
  * Fixed a bug that casued unexpected behavior when `pure` was used to inject
    values in Applicative composition of `ZipStream` and `ZipAsync` types.

  ## 0.1.1

  ### Enhancements
  * Make `cons` right associative and provide an operator form `.:` for it
  * Add `null`, `tail`, `reverse`, `replicateM`, `scan` stream operations
  * Improve performance of some stream operations (`foldl`, `dropWhile`)

  ### Bug Fixes
  * Fix the `product` operation. Earlier, it always returned 0 due to a bug
  * Fix the `last` operation, which returned `Nothing` for singleton streams

  ## 0.1.0

  * Initial release
basic-deps:
  exceptions: ! '>=0.8 && <0.11'
  heaps: ! '>=0.3 && <0.4'
  base: ! '>=4.8 && <5'
  monad-control: ! '>=1.0 && <2'
  lockfree-queue: ! '>=0.2.3 && <0.3'
  network: ! '>=2.6 && <4'
  containers: ! '>=0.5.8.2 && <0.7'
  ghc-prim: ! '>=0.2 && <0.6'
  atomic-primops: ! '>=0.8 && <0.9'
  mtl: ! '>=2.2 && <3'
  transformers-base: ! '>=0.4 && <0.5'
  transformers: ! '>=0.4 && <0.6'
  deepseq: ! '>=1.4.1 && <1.5'
  directory: ! '>=1.3 && <1.4'
all-versions:
- 0.1.0
- 0.1.1
- 0.1.2
- 0.2.0
- 0.2.1
- 0.3.0
- 0.4.0
- 0.4.1
- 0.5.0
- 0.5.1
- 0.5.2
- 0.6.0
- 0.6.1
- 0.7.0
author: Harendra Kumar
latest: 0.7.0
description-type: markdown
description: "# Streamly\n\n## Streaming Concurrently\n\nHaskell lists express pure
  computations using composable stream operations like\n`:`, `unfold`, `map`, `filter`,
  `zip` and `fold`.  Streamly is exactly like\nlists except that it can express sequences
  of pure as well as monadic\ncomputations aka streams. More importantly, it can express
  monadic sequences\nwith concurrent execution semantics without introducing any additional
  APIs.\n\nStreamly expresses concurrency using standard, well known abstractions.\nConcurrency
  semantics are defined for list operations, semigroup, applicative\nand monadic compositions.
  Programmer does not need to know any low level\nnotions of concurrency like threads,
  locking or synchronization.  Concurrent\nand non-concurrent programs are fundamentally
  the same.  A chosen segment of\nthe program can be made concurrent by annotating
  it with an appropriate\ncombinator.  We can choose a combinator for lookahead style
  or asynchronous\nconcurrency.  Concurrency is automatically scaled up or down based
  on the\ndemand from the consumer application, we can finally say goodbye to managing\nthread
  pools and associated sizing issues.  The result is truly fearless\nand declarative
  monadic concurrency.\n\n## Where to use streamly?\n\nStreamly is a general purpose
  programming framework.  It can be used equally\nefficiently from a simple `Hello
  World!` program to a massively concurrent\napplication. The answer to the question,
  \"where to use streamly?\" - would be\nsimilar to the answer to - \"Where to use
  Haskell lists or the IO monad?\".\n\nStreamly simplifies streaming and makes it
  as intuitive as plain lists. Unlike\nother streaming libraries, no fancy types are
  required.  Streamly is simply a\ngeneralization of Haskell lists to monadic streaming
  optionally with concurrent\ncomposition. The basic stream type in streamly `SerialT
  m a` can be considered\nas a list type `[a]` parameterized by the monad `m`. For
  example, `SerialT IO\na` is a moral equivalent of `[a]` in the IO monad. `SerialT
  Identity a`, is\nequivalent to pure lists.  Streams are constructed very much like
  lists, except\nthat they use `nil` and `cons` instead of `[]` and `:`.  Unlike lists,
  streams\ncan be constructed from monadic effects, not just pure elements.  Streams
  are\nprocessed just like lists, with list like combinators, except that they are\nmonadic
  and work in a streaming fashion. In other words streamly just completes\nwhat lists
  lack, you do not need to learn anything new. Please see [streamly vs\nlists](docs/streamly-vs-lists.md)
  for a detailed comparison.\n\nNot surprisingly, the monad instance of streamly is
  a list transformer, with\nconcurrency capability.\n\n## Why data flow programming?\n\nIf
  you need some convincing for using streaming or data flow programming\nparadigm
  itself then try to answer this question - why do we use lists in\nHaskell? It boils
  down to why we use functional programming in the first place.\nHaskell is successful
  in enforcing the functional data flow paradigm for pure\ncomputations using lists,
  but not for monadic computations. In the absence of a\nstandard and easy to use
  data flow programming paradigm for monadic\ncomputations, and the IO monad providing
  an escape hatch to an imperative\nmodel, we just love to fall into the imperative
  trap, and start asking the same\nfundamental question again - why do we have to
  use the streaming data model?\n\n## Comparative Performance\n\nHigh performance
  and simplicity are the two primary goals of streamly.\n`Streamly` employs two different
  stream representations (CPS and direct style)\nand interconverts between the two
  to get the best of both worlds on different\noperations. It uses both foldr/build
  (for CPS style) and stream fusion (for\ndirect style) techniques to fuse operations.
  In terms of performance,\nStreamly's goal is to compete with equivalent C programs.
  Streamly redefines\n\"blazing fast\" for streaming libraries, it competes with lists
  and `vector`.\nOther streaming libraries like \"streaming\", \"pipes\" and \"conduit\"
  are orders of\nmagnitude slower on most microbenchmarks.  See [streaming\nbenchmarks](https://github.com/composewell/streaming-benchmarks)
  for detailed\ncomparison.\n\nThe following chart shows a comparison of those streamly
  and list operations\nwhere performance of the two differs by more than 10%. Positive
  y-axis displays\nhow many times worse is a list operation compared to the same streamly\noperation,
  negative y-axis shows where streamly is worse compared to lists.\n\n![Streamly vs
  Lists (time) comparison](charts-0/streamly-vs-list-time.svg)\n\nStreamly uses lock-free
  synchronization for concurrent operations. It employs\nauto-scaling of the degree
  of concurrency based on demand. For CPU bound tasks\nit tries to keep the threads
  close to the number of CPUs available whereas for\nIO bound tasks more threads can
  be utilized. Parallelism can be utilized with\nlittle overhead even if the task
  size is very small.  See [concurrency\nbenchmarks](https://github.com/composewell/concurrency-benchmarks)
  for detailed\nperformance results and a comparison with the `async` package.\n\n##
  Installing and using\n\nPlease see [INSTALL.md](INSTALL.md) for instructions on
  how to use streamly\nwith your Haskell build tool or package manager. You may want
  to go through it\nbefore jumping to run the examples below.\n\nThe module `Streamly`
  provides just the core stream types, type casting and\nconcurrency control combinators.
  \ Stream construction, transformation, folding,\nmerging, zipping combinators are
  found in `Streamly.Prelude`.\n\n## Streaming Pipelines\n\nThe following snippet
  provides a simple stream composition example that reads\nnumbers from stdin, prints
  the squares of even numbers and exits if an even\nnumber more than 9 is entered.\n\n```
  haskell\nimport Streamly\nimport qualified Streamly.Prelude as S\nimport Data.Function
  ((&))\n\nmain = S.drain $\n       S.repeatM getLine\n     & fmap read\n     & S.filter
  even\n     & S.takeWhile (<= 9)\n     & fmap (\\x -> x * x)\n     & S.mapM print\n```\n\nUnlike
  `pipes` or `conduit` and like `vector` and `streaming`, `streamly`\ncomposes stream
  data instead of stream processors (functions).  A stream is\njust like a list and
  is explicitly passed around to functions that process the\nstream.  Therefore, no
  special operator is needed to join stages in a streaming\npipeline, just the standard
  function application (`$`) or reverse function\napplication (`&`) operator is enough.\n\n##
  Concurrent Stream Generation\n\n`consM` or its operator form `|:` can be used to
  construct a stream from\nmonadic actions. A stream constructed with `consM` can
  run the monadic actions\nin the stream concurrently when used with appropriate stream
  type combinator\n(e.g. `asyncly`, `aheadly` or `parallely`).\n\nThe following code
  finishes in 3 seconds (6 seconds when serial), note the\norder of elements in the
  resulting output, the outputs are consumed as soon as\neach action is finished (asyncly):\n\n```
  haskell\n> let p n = threadDelay (n * 1000000) >> return n\n> S.toList $ asyncly
  $ p 3 |: p 2 |: p 1 |: S.nil\n[1,2,3]\n```\n\nUse `aheadly` if you want speculative
  concurrency i.e. execute the actions in\nthe stream concurrently but consume the
  results in the specified order:\n\n``` haskell\n> S.toList $ aheadly $ p 3 |: p
  2 |: p 1 |: S.nil\n[3,2,1]\n```\n\nMonadic stream generation functions e.g. `unfoldrM`,
  `replicateM`, `repeatM`,\n`iterateM` and `fromFoldableM` etc. can work concurrently.\n\nThe
  following finishes in 10 seconds (100 seconds when serial):\n\n``` haskell\nS.drain
  $ asyncly $ S.replicateM 10 $ p 10\n```\n\n## Concurrency Auto Scaling\n\nConcurrency
  is auto-scaled i.e. more actions are executed concurrently if the\nconsumer is consuming
  the stream at a higher speed. How many tasks are executed\nconcurrently can be controlled
  by `maxThreads` and how many results are\nbuffered ahead of consumption can be controlled
  by `maxBuffer`. See the\ndocumentation in the `Streamly` module.\n\n## Concurrent
  Streaming Pipelines\n\nUse `|&` or `|$` to apply stream processing functions concurrently.
  The\nfollowing example prints a \"hello\" every second; if you use `&` instead of\n`|&`
  you will see that the delay doubles to 2 seconds instead because of serial\napplication.\n\n```
  haskell\nmain = S.drain $\n      S.repeatM (threadDelay 1000000 >> return \"hello\")\n
  \  |& S.mapM (\\x -> threadDelay 1000000 >> putStrLn x)\n```\n\n## Mapping Concurrently\n\nWe
  can use `mapM` or `sequence` functions concurrently on a stream.\n\n``` haskell\n>
  let p n = threadDelay (n * 1000000) >> return n\n> S.drain $ aheadly $ S.mapM (\\x
  -> p 1 >> print x) (serially $ repeatM (p 1))\n```\n\n## Serial and Concurrent Merging\n\nSemigroup
  and Monoid instances can be used to fold streams serially or\nconcurrently. In the
  following example we compose ten actions in the\nstream, each with a delay of 1
  to 10 seconds, respectively. Since all the\nactions are concurrent we see one output
  printed every second:\n\n``` haskell\nimport Streamly\nimport qualified Streamly.Prelude
  as S\nimport Control.Concurrent (threadDelay)\n\nmain = S.toList $ parallely $ foldMap
  delay [1..10]\n where delay n = S.yieldM $ threadDelay (n * 1000000) >> print n\n```\n\nStreams
  can be combined together in many ways. We provide some examples\nbelow, see the
  tutorial for more ways. We use the following `delay`\nfunction in the examples to
  demonstrate the concurrency aspects:\n\n``` haskell\nimport Streamly\nimport qualified
  Streamly.Prelude as S\nimport Control.Concurrent\n\ndelay n = S.yieldM $ do\n    threadDelay
  (n * 1000000)\n    tid <- myThreadId\n    putStrLn (show tid ++ \": Delay \" ++
  show n)\n```\n### Serial\n\n``` haskell\nmain = S.drain $ delay 3 <> delay 2 <>
  delay 1\n```\n```\nThreadId 36: Delay 3\nThreadId 36: Delay 2\nThreadId 36: Delay
  1\n```\n\n### Parallel\n\n``` haskell\nmain = S.drain . parallely $ delay 3 <> delay
  2 <> delay 1\n```\n```\nThreadId 42: Delay 1\nThreadId 41: Delay 2\nThreadId 40:
  Delay 3\n```\n\n## Nested Loops (aka List Transformer)\n\nThe monad instance composes
  like a list monad.\n\n``` haskell\nimport Streamly\nimport qualified Streamly.Prelude
  as S\n\nloops = do\n    x <- S.fromFoldable [1,2]\n    y <- S.fromFoldable [3,4]\n
  \   S.yieldM $ putStrLn $ show (x, y)\n\nmain = S.drain loops\n```\n```\n(1,3)\n(1,4)\n(2,3)\n(2,4)\n```\n\n##
  Concurrent Nested Loops\n\nTo run the above code with speculative concurrency i.e.
  each iteration in the\nloop can run concurrently but the results are presented to
  the consumer of the\noutput in the same order as serial execution:\n\n``` haskell\nmain
  = S.drain $ aheadly $ loops\n```\n\nDifferent stream types execute the loop iterations
  in different ways. For\nexample, `wSerially` interleaves the loop iterations. There
  are several\nconcurrent stream styles to execute the loop iterations concurrently
  in\ndifferent ways, see the `Streamly.Tutorial` module for a detailed treatment.\n\n##
  Magical Concurrency\n\nStreams can perform semigroup (<>) and monadic bind (>>=)
  operations\nconcurrently using combinators like `asyncly`, `parallelly`. For example,\nto
  concurrently generate squares of a stream of numbers and then concurrently\nsum
  the square roots of all combinations of two streams:\n\n``` haskell\nimport Streamly\nimport
  qualified Streamly.Prelude as S\n\nmain = do\n    s <- S.sum $ asyncly $ do\n        --
  Each square is performed concurrently, (<>) is concurrent\n        x2 <- foldMap
  (\\x -> return $ x * x) [1..100]\n        y2 <- foldMap (\\y -> return $ y * y)
  [1..100]\n        -- Each addition is performed concurrently, monadic bind is concurrent\n
  \       return $ sqrt (x2 + y2)\n    print s\n```\n\nThe concurrency facilities
  provided by streamly can be compared with\n[OpenMP](https://en.wikipedia.org/wiki/OpenMP)
  and\n[Cilk](https://en.wikipedia.org/wiki/Cilk) but with a more declarative\nexpression.\n\n##
  Example: Listing Directories Recursively/Concurrently\n\nThe following code snippet
  lists a directory tree recursively, reading multiple\ndirectories concurrently:\n\n```haskell\nimport
  Control.Monad.IO.Class (liftIO)\nimport Path.IO (listDir, getCurrentDir) -- from
  path-io package\nimport Streamly (AsyncT, adapt)\nimport qualified Streamly.Prelude
  as S\n\nlistDirRecursive :: AsyncT IO ()\nlistDirRecursive = getCurrentDir >>= readdir
  >>= liftIO . mapM_ putStrLn\n  where\n    readdir dir = do\n      (dirs, files)
  <- listDir dir\n      S.yield (map show dirs ++ map show files) <> foldMap readdir
  dirs\n\nmain :: IO ()\nmain = S.drain $ adapt $ listDirRecursive\n```\n\n`AsyncT`
  is a stream monad transformer. If you are familiar with a list\ntransformer, it
  is nothing but `ListT` with concurrency semantics. For example,\nthe semigroup operation
  `<>` is concurrent. This makes `foldMap` concurrent\ntoo. You can replace `AsyncT`
  with `SerialT` and the above code will become\nserial, exactly equivalent to a `ListT`.\n\n##
  Rate Limiting\n\nFor bounded concurrent streams, stream yield rate can be specified.
  For\nexample, to print hello once every second you can simply write this:\n\n```
  haskell\nimport Streamly\nimport Streamly.Prelude as S\n\nmain = S.drain $ asyncly
  $ avgRate 1 $ S.repeatM $ putStrLn \"hello\"\n```\n\nFor some practical uses of
  rate control, see\n[AcidRain.hs](https://github.com/composewell/streamly/tree/master/examples/AcidRain.hs)\nand\n[CirclingSquare.hs](https://github.com/composewell/streamly/tree/master/examples/CirclingSquare.hs)\n.\nConcurrency
  of the stream is automatically controlled to match the specified\nrate. Rate control
  works precisely even at throughputs as high as millions of\nyields per second. For
  more sophisticated rate control see the haddock\ndocumentation.\n\n## Arrays\n\nThe
  `Streamly.Memory.Array` module provides immutable arrays.  Arrays are the\ncomputing
  duals of streams. Streams are good at sequential access and immutable\ntransformations
  of in-transit data whereas arrays are good at random access and\nin-place transformations
  of buffered data. Unlike streams which are potentially\ninfinite, arrays are necessarily
  finite. Arrays can be used as an efficient\ninterface between streams and external
  storage systems like memory, files and\nnetwork. Streams and arrays complete each
  other to provide a general purpose\ncomputing system. The design of streamly as
  a general purpose computing\nframework is centered around these two fundamental
  aspects of computing and\nstorage.\n\n`Streamly.Memory.Array` uses pinned memory
  outside GC and therefore avoid any\nGC overhead for the storage in arrays. Streamly
  allows efficient\ntransformations over arrays using streams. It uses arrays to transfer
  data to\nand from the operating system and to store data in memory.\n\n## Folds\n\nFolds
  are consumers of streams.  `Streamly.Data.Fold` module provides a `Fold`\ntype that
  represents a `foldl'`.  Such folds can be efficiently composed\nallowing the compiler
  to perform stream fusion and therefore implement high\nperformance combinators for
  consuming streams. A stream can be distributed to\nmultiple folds, or it can be
  partitioned across multiple folds, or\ndemultiplexed over multiple folds, or unzipped
  to two folds. We can also use\nfolds to fold segments of stream generating a stream
  of the folded results.\n\nIf you are familiar with the `foldl` library, these are
  the same composable\nleft folds but simpler and better integrated with streamly,
  and with many more\npowerful ways of composing and applying them.\n\n## Unfolds\n\nUnfolds
  are duals of folds. Folds help us compose consumers of streams\nefficiently and
  unfolds help us compose producers of streams efficiently.\n`Streamly.Data.Unfold`
  provides an `Unfold` type that represents an `unfoldr`\nor a stream generator. Such
  generators can be combined together efficiently\nallowing the compiler to perform
  stream fusion and implement high performance\nstream merging combinators.\n\n##
  File IO\n\nThe following code snippets implement some common Unix command line utilities\nusing
  streamly.  You can compile these with `ghc -O2 -fspec-constr-recursive=16\n-fmax-worker-args=16`
  and compare the performance with regular GNU coreutils\navailable on your system.
  \ Though many of these are not most optimal solutions\nto keep them short and elegant.
  Source file\n[HandleIO.hs](https://github.com/composewell/streamly/tree/master/examples/HandleIO.hs)\nin
  the examples directory includes these examples.\n\n``` haskell\nmodule Main where\n\nimport
  qualified Streamly.Prelude as S\nimport qualified Streamly.Data.Fold as FL\nimport
  qualified Streamly.Memory.Array as A\nimport qualified Streamly.FileSystem.Handle
  as FH\nimport qualified System.IO as FH\n\nimport Data.Char (ord)\nimport System.Environment
  (getArgs)\nimport System.IO (openFile, IOMode(..), stdout)\n\nwithArg f = do\n    (name
  : _) <- getArgs\n    src <- openFile name ReadMode\n    f src\n\nwithArg2 f = do\n
  \   (sname : dname : _) <- getArgs\n    src <- openFile sname ReadMode\n    dst
  <- openFile dname WriteMode\n    f src dst\n```\n\n### cat\n\n``` haskell\ncat =
  S.fold (FH.writeChunks stdout) . S.unfold FH.readChunks\nmain = withArg cat\n```\n\n###
  cp\n\n``` haskell\ncp src dst = S.fold (FH.writeChunks dst) $ S.unfold FH.readChunks
  src\nmain = withArg2 cp\n```\n\n### wc -l\n\n``` haskell\nwcl = S.length . S.splitOn
  (== 10) FL.drain . S.unfold FH.read\nmain = withArg wcl >>= print\n```\n\n### Average
  Line Length\n\n``` haskell\navgll =\n      S.fold avg\n    . S.splitOn (== 10) FL.length\n
  \   . S.unfold FH.read\n\n    where avg      = (/) <$> toDouble FL.sum <*> toDouble
  FL.length\n          toDouble = fmap (fromIntegral :: Int -> Double)\n\nmain = withArg
  avgll >>= print\n```\n\n### Line Length Histogram\n\n`classify` is not released
  yet, and is available in\n`Streamly.Internal.Data.Fold`\n\n``` haskell\nllhisto
  =\n      S.fold (FL.classify FL.length)\n    . S.map bucket\n    . S.splitOn (==
  10) FL.length\n    . S.unfold FH.read\n\n    where\n    bucket n = let i = n `mod`
  10 in if i > 9 then (9,n) else (i,n)\n\nmain = withArg llhisto >>= print\n```\n\n##
  Socket IO\n\nIts easy to build concurrent client and server programs using streamly.\n`Streamly.Network.*`
  modules provide easy combinators to build network servers\nand client programs using
  streamly. See\n[FromFileClient.hs](https://github.com/composewell/streamly/tree/master/examples/FromFileClient.hs),\n[EchoServer.hs](https://github.com/composewell/streamly/tree/master/examples/EchoServer.hs),\n[FileSinkServer.hs](https://github.com/composewell/streamly/tree/master/examples/FileSinkServer.hs)\nin
  the examples directory.\n\n## Exceptions\n\nExceptions can be thrown at any point
  using the `MonadThrow` instance. Standard\nexception handling combinators like `bracket`,
  `finally`, `handle`,\n`onException` are provided in `Streamly.Prelude` module.\n\nIn
  presence of concurrency, synchronous exceptions work just the way they are\nsupposed
  to work in non-concurrent code. When concurrent streams\nare combined together,
  exceptions from the constituent streams are propagated\nto the consumer stream.
  When an exception occurs in any of the constituent\nstreams other concurrent streams
  are promptly terminated. \n\nThere is no notion of explicit threads in streamly,
  therefore, no\nasynchronous exceptions to deal with. You can just ignore the zillions
  of\nblogs, talks, caveats about async exceptions. Async exceptions just don't\nexist.
  \ Please don't use things like `myThreadId` and `throwTo` just for fun!\n\n## Reactive
  Programming (FRP)\n\nStreamly is a foundation for first class reactive programming
  as well by virtue\nof integrating concurrency and streaming. See\n[AcidRain.hs](https://github.com/composewell/streamly/tree/master/examples/AcidRain.hs)\nfor
  a console based FRP game example and\n[CirclingSquare.hs](https://github.com/composewell/streamly/tree/master/examples/CirclingSquare.hs)\nfor
  an SDL based animation example.\n\n## Conclusion\n\nStreamly, short for streaming
  concurrently, provides monadic streams, with a\nsimple API, almost identical to
  standard lists, and an in-built\nsupport for concurrency.  By using stream-style
  combinators on stream\ncomposition, streams can be generated, merged, chained, mapped,
  zipped, and\nconsumed concurrently – providing a generalized high level programming\nframework
  unifying streaming and concurrency. Controlled concurrency allows\neven infinite
  streams to be evaluated concurrently.  Concurrency is auto scaled\nbased on feedback
  from the stream consumer.  The programmer does not have to be\naware of threads,
  locking or synchronization to write scalable concurrent\nprograms.\n\nStreamly is
  a programmer first library, designed to be useful and friendly to\nprogrammers for
  solving practical problems in a simple and concise manner. Some\nkey points in favor
  of streamly are:\n\n  * _Simplicity_: Simple list like streaming API, if you know
  how to use lists\n    then you know how to use streamly. This library is built with
  simplicity\n    and ease of use as a design goal.\n  * _Concurrency_: Simple, powerful,
  and scalable concurrency.  Concurrency is\n    built-in, and not intrusive, concurrent
  programs are written exactly the\n    same way as non-concurrent ones.\n  * _Generality_:
  Unifies functionality provided by several disparate packages\n    (streaming, concurrency,
  list transformer, logic programming, reactive\n    programming) in a concise API.\n
  \ * _Performance_: Streamly is designed for high performance. It employs stream\n
  \   fusion optimizations for best possible performance. Serial peformance is\n    equivalent
  to the venerable `vector` library in most cases and even better\n    in some cases.
  \ Concurrent performance is unbeatable.  See\n    [streaming-benchmarks](https://github.com/composewell/streaming-benchmarks)\n
  \   for a comparison of popular streaming libraries on micro-benchmarks.\n\nThe
  basic streaming functionality of streamly is equivalent to that provided by\nstreaming
  libraries like\n[vector](https://hackage.haskell.org/package/vector),\n[streaming](https://hackage.haskell.org/package/streaming),\n[pipes](https://hackage.haskell.org/package/pipes),
  and\n[conduit](https://hackage.haskell.org/package/conduit).\nIn addition to providing
  streaming functionality, streamly subsumes\nthe functionality of list transformer
  libraries like `pipes` or\n[list-t](https://hackage.haskell.org/package/list-t),
  and also the logic\nprogramming library [logict](https://hackage.haskell.org/package/logict).
  On\nthe concurrency side, it subsumes the functionality of the\n[async](https://hackage.haskell.org/package/async)
  package, and provides even\nhigher level concurrent composition. Because it supports\nstreaming
  with concurrency we can write FRP applications similar in concept to\n[Yampa](https://hackage.haskell.org/package/Yampa)
  or\n[reflex](https://hackage.haskell.org/package/reflex).\n\nSee the `Comparison
  with existing packages` section at the end of the\n[tutorial](https://hackage.haskell.org/package/streamly/docs/Streamly-Tutorial.html).\n\n##
  Further Reading\n\nFor more information, see:\n\n  * [Detailed tutorial](https://hackage.haskell.org/package/streamly/docs/Streamly-Tutorial.html)\n
  \ * [Reference documentation](https://hackage.haskell.org/package/streamly)\n  *
  [Examples](examples)\n  * [Guides](docs)\n  * [Streaming benchmarks](https://github.com/composewell/streaming-benchmarks)\n
  \ * [Concurrency benchmarks](https://github.com/composewell/concurrency-benchmarks)\n\nFor
  additional unreleased/experimental APIs, build the haddock docs using:\n\n```\n$
  cabal haddock --haddock-option=\"--show-all\"\n$ stack haddock --haddock-arguments
  \"--show-all\" --no-haddock-deps\n```\n\n## Support\n\nPlease feel free to ask questions
  on the\n[streamly gitter channel](https://gitter.im/composewell/streamly).\nIf you
  require professional support, consulting, training or timely\nenhancements to the
  library please contact\n[support@composewell.com](mailto:support@composewell.com).\n\n##
  Credits\n\nThe following authors/libraries have influenced or inspired this library
  in a\nsignificant way:\n\n  * Roman Leshchinskiy (vector)\n  * Gabriel Gonzalez
  (foldl)\n  * Alberto G. Corona (transient)\n\nSee the `credits` directory for full
  list of contributors, credits and licenses.\n\n## Contributing\n\nThe code is available
  under BSD-3 license\n[on github](https://github.com/composewell/streamly). Join
  the [gitter\nchat](https://gitter.im/composewell/streamly) channel for discussions.
  \ Please\nask any questions on the gitter channel or [contact the maintainer\ndirectly](mailto:streamly@composewell.com).
  All contributions are welcome!\n"
license-name: BSD-3-Clause
