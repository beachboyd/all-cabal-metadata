homepage: https://github.com/composewell/streamly
changelog-type: markdown
hash: 5a00c20700bfbe37b356dcdca5db8866d41661223bf8593cbbe4906ef553df36
test-bench-deps:
  exceptions: ! '>=0.8 && <0.11'
  heaps: ! '>=0.3 && <0.4'
  base: ! '>=4.8 && <5'
  hspec: ! '>=2.0 && <3'
  clock: ! '>=0.7.1 && <0.8'
  monad-control: ! '>=1.0 && <2'
  lockfree-queue: ! '>=0.2.3 && <0.3'
  gauge: ! '>=0.2.4 && <0.3'
  containers: ! '>=0.5 && <0.7'
  ghc-prim: ! '>=0.2 && <0.6'
  atomic-primops: ! '>=0.8 && <0.9'
  mtl: ! '>=2.2 && <3'
  transformers-base: ! '>=0.4 && <0.5'
  transformers: ! '>=0.4 && <0.6'
  random: ! '>=1.0.0 && <1.2'
  deepseq: ! '>=1.4.0 && <1.5'
  QuickCheck: ! '>=2.10 && <2.13'
  streamly: -any
maintainer: harendra.kumar@gmail.com
synopsis: Beautiful Streaming, Concurrent and Reactive Composition
changelog: ! "## 0.5.2\n\n### Bug Fixes\n\n* Cleanup any pending threads when an exception
  occurs.\n* Fixed a livelock in ahead style streams. The problem manifests sometimes
  when\n  multiple streams are merged together in ahead style and one of them is a
  nil\n  stream.\n* As per expected concurrency semantics each forked concurrent task
  must run\n  with the monadic state captured at the fork point.  This release fixes
  a bug,\n  which, in some cases caused an incorrect monadic state to be used for
  a\n  concurrent action, leading to unexpected behavior when concurrent streams are\n
  \ used in a stateful monad e.g. `StateT`. Particularly, this bug cannot affect\n
  \ `ReaderT`.\n\n## 0.5.1\n\n* Performance improvements, especially space consumption,
  for concurrent\n  streams\n\n## 0.5.0\n\n### Bug Fixes\n\n* Leftover threads are
  now cleaned up as soon as the consumer is garbage\n  collected.\n* Fix a bug in
  concurrent function application that in certain cases would\n  unnecessarily share
  the concurrency state resulting in incorrect output\n  stream.\n* Fix passing of
  state across `parallel`, `async`, `wAsync`, `ahead`, `serial`,\n  `wSerial` combinators.
  Without this fix combinators that rely on state\n  passing e.g.  `maxThreads` and
  `maxBuffer` won't work across these\n  combinators.\n\n### Enhancements\n\n* Added
  rate limiting combinators `rate`, `avgRate`, `minRate`, `maxRate` and\n  `constRate`
  to control the yield rate of a stream.\n* Add `foldl1'`, `foldr1`, `intersperseM`,
  `find`, `lookup`, `and`, `or`,\n  `findIndices`, `findIndex`, `elemIndices`, `elemIndex`,
  `init` to Prelude\n\n### Deprecations\n\n* The `Streamly.Time` module is now deprecated,
  its functionality is subsumed\n  by the new rate limiting combinators.\n\n## 0.4.1\n\n###
  Bug Fixes\n\n* foldxM was not fully strict, fixed.\n\n## 0.4.0\n\n### Breaking changes\n\n*
  Signatures of `zipWithM` and `zipAsyncWithM` have changed\n* Some functions in prelude
  now require an additional `Monad` constraint on\n  the underlying type of the stream.\n\n###
  Deprecations\n\n* `once` has been deprecated and renamed to `yieldM`\n\n### Enhancements\n\n*
  Add concurrency control primitives `maxThreads` and `maxBuffer`.\n* Concurrency
  of a stream with bounded concurrency when used with `take` is now\n  limited by
  the number of elements demanded by `take`.\n* Significant performance improvements
  utilizing stream fusion optimizations.\n* Add `yield` to construct a singleton stream
  from a pure value\n* Add `repeat` to generate an infinite stream by repeating a
  pure value\n* Add `fromList` and `fromListM` to generate streams from lists, faster
  than\n  `fromFoldable` and `fromFoldableM`\n* Add `map` as a synonym of fmap\n*
  Add `scanlM'`, the monadic version of scanl'\n* Add `takeWhileM` and `dropWhileM`\n*
  Add `filterM`\n\n## 0.3.0\n\n### Breaking changes\n\n* Some prelude functions, to
  whom concurrency capability has been added, will\n  now require a `MonadAsync` constraint.\n\n###
  Bug Fixes\n\n* Fixed a race due to which, in a rare case, we might block indefinitely
  on\n  an MVar due to a lost wakeup.\n* Fixed an issue in adaptive concurrency. The
  issue caused us to stop creating\n  more worker threads in some cases due to a race.
  This bug would not cause any\n  functional issue but may reduce concurrency in some
  cases.\n\n### Enhancements\n* Added a concurrent lookahead stream type `Ahead`\n*
  Added `fromFoldableM` API that creates a stream from a container of monadic\n  actions\n*
  Monadic stream generation functions `consM`, `|:`, `unfoldrM`, `replicateM`,\n  `repeatM`,
  `iterateM` and `fromFoldableM` can now generate streams\n  concurrently when used
  with concurrent stream types.\n* Monad transformation functions `mapM` and `sequence`
  can now map actions\n  concurrently when used at appropriate stream types.\n* Added
  concurrent function application operators to run stages of a\n  stream processing
  function application pipeline concurrently.\n* Added `mapMaybe` and `mapMaybeM`.\n\n##
  0.2.1\n\n### Bug Fixes\n* Fixed a bug that caused some transformation ops to return
  incorrect results\n  when used with concurrent streams. The affected ops are `take`,
  `filter`,\n  `takeWhile`, `drop`, `dropWhile`, and `reverse`.\n\n## 0.2.0\n\n###
  Breaking changes\n* Changed the semantics of the Semigroup instance for `InterleavedT`,
  `AsyncT`\n  and `ParallelT`. The new semantics are as follows:\n  * For `InterleavedT`,
  `<>` operation interleaves two streams\n  * For `AsyncT`, `<>` now concurrently
  merges two streams in a left biased\n    manner using demand based concurrency.\n
  \ * For `ParallelT`, the `<>` operation now concurrently meges the two streams\n
  \   in a fairly parallel manner.\n\n  To adapt to the new changes, replace `<>`
  with `serial` wherever it is used\n  for stream types other than `StreamT`.\n\n*
  Remove the `Alternative` instance.  To adapt to this change replace any usage\n
  \ of `<|>` with `parallel` and `empty` with `nil`.\n* Stream type now defaults to
  the `SerialT` type unless explicitly specified\n  using a type combinator or a monomorphic
  type.  This change reduces puzzling\n  type errors for beginners. It includes the
  following two changes:\n  * Change the type of all stream elimination functions
  to use `SerialT`\n    instead of a polymorphic type. This makes sure that the stream
  type is\n    always fixed at all exits.\n  * Change the type combinators (e.g. `parallely`)
  to only fix the argument\n    stream type and the output stream type remains polymorphic.\n\n
  \ Stream types may have to be changed or type combinators may have to be added\n
  \ or removed to adapt to this change.\n* Change the type of `foldrM` to make it
  consistent with `foldrM` in base.\n* `async` is renamed to `mkAsync` and `async`
  is now a new API with a different\n  meaning.\n* `ZipAsync` is renamed to `ZipAsyncM`
  and `ZipAsync` is now ZipAsyncM\n  specialized to the IO Monad.\n* Remove the `MonadError`
  instance as it was not working correctly for\n  parallel compositions. Use `MonadThrow`
  instead for error propagation.\n* Remove Num/Fractional/Floating instances as they
  are not very useful. Use\n  `fmap` and `liftA2` instead.\n\n### Deprecations\n*
  Deprecate and rename the following symbols:\n    * `Streaming` to `IsStream`\n    *
  `runStreaming` to `runStream`\n    * `StreamT` to `SerialT`\n    * `InterleavedT`
  to `WSerialT`\n    * `ZipStream` to `ZipSerialM`\n    * `ZipAsync` to `ZipAsyncM`\n
  \   * `interleaving` to `wSerially`\n    * `zipping` to `zipSerially`\n    * `zippingAsync`
  to `zipAsyncly`\n    * `<=>` to `wSerial`\n    * `<|` to `async`\n    * `each` to
  `fromFoldable`\n    * `scan` to `scanx`\n    * `foldl` to `foldx`\n    * `foldlM`
  to `foldxM`\n* Deprecate the following symbols for future removal:\n    * `runStreamT`\n
  \   * `runInterleavedT`\n    * `runAsyncT`\n    * `runParallelT`\n    * `runZipStream`\n
  \   * `runZipAsync`\n\n### Enhancements\n* Add the following functions:\n    * `consM`
  and `|:` operator to construct streams from monadic actions\n    * `once` to create
  a singleton stream from a monadic action\n    * `repeatM` to construct a stream
  by repeating a monadic action\n    * `scanl'` strict left scan\n    * `foldl'` strict
  left fold\n    * `foldlM'` strict left fold with a monadic fold function\n    *
  `serial` run two streams serially one after the other\n    * `async` run two streams
  asynchronously\n    * `parallel` run two streams in parallel (replaces `<|>`)\n
  \   * `WAsyncT` stream type for BFS version of `AsyncT` composition\n* Add simpler
  stream types that are specialized to the IO monad\n* Put a bound (1500) on the output
  buffer used for asynchronous tasks\n* Put a limit (1500) on the number of threads
  used for Async and WAsync types\n\n## 0.1.2\n\n### Enhancements\n* Add `iterate`,
  `iterateM` stream operations\n\n### Bug Fixes\n* Fixed a bug that casued unexpected
  behavior when `pure` was used to inject\n  values in Applicative composition of
  `ZipStream` and `ZipAsync` types.\n\n## 0.1.1\n\n### Enhancements\n* Make `cons`
  right associative and provide an operator form `.:` for it\n* Add `null`, `tail`,
  `reverse`, `replicateM`, `scan` stream operations\n* Improve performance of some
  stream operations (`foldl`, `dropWhile`)\n\n### Bug Fixes\n* Fix the `product` operation.
  Earlier, it always returned 0 due to a bug\n* Fix the `last` operation, which returned
  `Nothing` for singleton streams\n\n## 0.1.0\n\n* Initial release\n"
basic-deps:
  exceptions: ! '>=0.8 && <0.11'
  heaps: ! '>=0.3 && <0.4'
  base: ! '>=4.8 && <5'
  clock: ! '>=0.7.1 && <0.8'
  monad-control: ! '>=1.0 && <2'
  lockfree-queue: ! '>=0.2.3 && <0.3'
  containers: ! '>=0.5 && <0.7'
  ghc-prim: ! '>=0.2 && <0.6'
  atomic-primops: ! '>=0.8 && <0.9'
  mtl: ! '>=2.2 && <3'
  transformers-base: ! '>=0.4 && <0.5'
  transformers: ! '>=0.4 && <0.6'
all-versions:
- 0.1.0
- 0.1.1
- 0.1.2
- 0.2.0
- 0.2.1
- 0.3.0
- 0.4.0
- 0.4.1
- 0.5.0
- 0.5.1
- 0.5.2
author: Harendra Kumar
latest: 0.5.2
description-type: markdown
description: ! "# Streamly\n\n## Streaming Concurrently\n\nHaskell lists express pure
  computations using composable stream operations like\n`:`, `unfold`, `map`, `filter`,
  `zip` and `fold`.  Streamly is exactly like\nlists except that it can express sequences
  of pure as well as monadic\ncomputations aka streams. More importantly, it can express
  monadic sequences\nwith concurrent execution semantics without introducing any additional
  APIs.\n\nStreamly expresses concurrency using standard, well known abstractions.\nConcurrency
  semantics are defined for list operations, semigroup, applicative\nand monadic compositions.
  Programmer does not need to know any low level\nnotions of concurrency like threads,
  locking or synchronization.  Concurrent\nand non-concurrent programs are fundamentally
  the same.  A chosen segment of\nthe program can be made concurrent by annotating
  it with an appropriate\ncombinator.  We can choose a combinator for lookahead style
  or asynchronous\nconcurrency.  Concurrency is automatically scaled up or down based
  on the\ndemand from the consumer application, we can finally say goodbye to managing\nthread
  pools and associated sizing issues.  The result is truly fearless\nand declarative
  monadic concurrency.\n\n## Where to use streamly?\n\nStreamly is a general purpose
  programming framwework.  It can be used equally\nefficiently from a simple `Hello
  World!` program to a massively concurrent\napplication. The answer to the question,
  \"where to use streamly?\" - would be\nsimilar to the answer to - \"Where to use
  Haskell lists or the IO monad?\".\nStreamly generalizes lists to monadic streams,
  and the `IO` monad to\nnon-deterministic and concurrent stream composition. The
  `IO` monad is a\nspecial case of streamly; if we use single element streams the
  behavior of\nstreamly becomes identical to the IO monad.  The IO monad code can
  be replaced\nwith streamly by just prefixing the IO actions with `liftIO`, without
  any other\nchanges, and without any loss of performance.  Pure lists too are a special\ncase
  of streamly; if we use `Identity` as the underlying monad, streamly\nstreams turn
  into pure lists.  Non-concurrent programs are just a special case\nof concurrent
  ones, simply adding a combinator turns a non-concurrent program\ninto a concurrent
  one.\n\nIn other words, streamly combines the functionality of lists and IO, with\nbuiltin
  concurrency.  If you want to write a program that involves IO,\nconcurrent or not,
  then you can just use streamly as the base monad, in fact,\nyou could even use streamly
  for pure computations, as streamly performs at par\nwith pure lists or `vector`.\n\n##
  Why data flow programming?\n\nIf you need some convincing for using streaming or
  data flow programming\nparadigm itself then try to answer this question - why do
  we use lists in\nHaskell? It boils down to why we use functional programming in
  the first place.\nHaskell is successful in enforcing the functional data flow paradigm
  for pure\ncomputations using lists, but not for monadic computations. In the absence
  of a\nstandard and easy to use data flow programming paradigm for monadic\ncomputations,
  and the IO monad providing an escape hatch to an imperative\nmodel, we just love
  to fall into the imperative trap, and start asking the same\nfundamental question
  again - why do we have to use the streaming data model?\n\n## Show me an example\n\nHere
  is an IO monad code to list a directory recursively:\n\n```haskell\nimport Control.Monad.IO.Class
  (liftIO)\nimport Path.IO (listDir, getCurrentDir) -- from path-io package\n\nlistDirRecursive
  = getCurrentDir >>= readdir\n  where\n    readdir dir = do\n      (dirs, files)
  <- listDir dir\n      liftIO $ mapM_ putStrLn\n             $ map show dirs ++ map
  show files\n      foldMap readdir dirs\n```\n\nThis is your usual IO monad code,
  with no streamly specific code whatsoever.\nThis is how you can run this:\n\n```
  haskell\nmain :: IO ()\nmain = listDirRecursive\n```\n\nAnd, this is how you can
  run exactly the same code using streamly with\nlookahead style concurrency, the
  only difference is that this time multiple\ndirectories are read concurrently:\n\n```
  haskell\nimport Streamly (runStream, aheadly)\n\nmain :: IO ()\nmain = runStream
  $ aheadly $ listDirRecursive\n```\n\nIsn't that magical? What's going on here? Streamly
  does not introduce any new\nabstractions, it just uses standard abstractions like
  `Semigroup` or\n`Monoid` to combine monadic streams concurrently, the way lists
  combine a\nsequence of pure values non-concurrently. The `foldMap` in the code\nabove
  turns into a concurrent monoidal composition of a stream of `readdir`\ncomputations.\n\n##
  How does it perform?\n\nProviding monadic streaming and high level declarative concurrency
  does not\nmean that `streamly` compromises with performance in any way. The\nnon-concurrent
  performance of `streamly` competes with lists and the `vector`\nlibrary. The concurrent
  performance is as good as it gets, see [concurrency\nbenchmarks](https://github.com/composewell/concurrency-benchmarks)
  for detailed\nperformance results and a comparison with the `async` package.\n\nThe
  following chart shows a summary of the cost of key streaming operations\nprocessing
  a million elements. The timings for `streamly` and `vector` are in\nthe 600-700
  microseconds range and therefore can barely be seen in the graph.\nFor more details,
  see [streaming\nbenchmarks](https://github.com/composewell/streaming-benchmarks).\n\n![Streaming
  Operations at a Glance](charts-0/KeyOperations-time.svg)\n\n## Streaming Pipelines\n\nThe
  following snippet provides a simple stream composition example that reads\nnumbers
  from stdin, prints the squares of even numbers and exits if an even\nnumber more
  than 9 is entered.\n\n``` haskell\nimport Streamly\nimport qualified Streamly.Prelude
  as S\nimport Data.Function ((&))\n\nmain = runStream $\n       S.repeatM getLine\n
  \    & fmap read\n     & S.filter even\n     & S.takeWhile (<= 9)\n     & fmap (\\x
  -> x * x)\n     & S.mapM print\n```\n\nUnlike `pipes` or `conduit` and like `vector`
  and `streaming`, `streamly`\ncomposes stream data instead of stream processors (functions).
  \ A stream is\njust like a list and is explicitly passed around to functions that
  process the\nstream.  Therefore, no special operator is needed to join stages in
  a streaming\npipeline, just the standard function application (`$`) or reverse function\napplication
  (`&`) operator is enough.  Combinators are provided in\n`Streamly.Prelude` to transform
  or fold streams.\n\n## Concurrent Stream Generation\n\nMonadic construction and
  generation functions e.g. `consM`, `unfoldrM`,\n`replicateM`, `repeatM`, `iterateM`
  and `fromFoldableM` etc. work concurrently\nwhen used with appropriate stream type
  combinator (e.g. `asyncly`, `aheadly` or\n`parallely`).\n\nThe following code finishes
  in 3 seconds (6 seconds when serial):\n\n``` haskell\n> let p n = threadDelay (n
  * 1000000) >> return n\n> S.toList $ aheadly $ p 3 |: p 2 |: p 1 |: S.nil\n[3,2,1]\n\n>
  S.toList $ parallely $ p 3 |: p 2 |: p 1 |: S.nil\n[1,2,3]\n```\n\nThe following
  finishes in 10 seconds (100 seconds when serial):\n\n``` haskell\nrunStream $ asyncly
  $ S.replicateM 10 $ p 10\n```\n\n## Concurrent Streaming Pipelines\n\nUse `|&` or
  `|$` to apply stream processing functions concurrently. The\nfollowing example prints
  a \"hello\" every second; if you use `&` instead of\n`|&` you will see that the
  delay doubles to 2 seconds instead because of serial\napplication.\n\n``` haskell\nmain
  = runStream $\n      S.repeatM (threadDelay 1000000 >> return \"hello\")\n   |&
  S.mapM (\\x -> threadDelay 1000000 >> putStrLn x)\n```\n\n## Mapping Concurrently\n\nWe
  can use `mapM` or `sequence` functions concurrently on a stream.\n\n``` haskell\n>
  let p n = threadDelay (n * 1000000) >> return n\n> runStream $ aheadly $ S.mapM
  (\\x -> p 1 >> print x) (serially $ repeatM (p 1))\n```\n\n## Serial and Concurrent
  Merging\n\nSemigroup and Monoid instances can be used to fold streams serially or\nconcurrently.
  In the following example we compose ten actions in the\nstream, each with a delay
  of 1 to 10 seconds, respectively. Since all the\nactions are concurrent we see one
  output printed every second:\n\n``` haskell\nimport Streamly\nimport qualified Streamly.Prelude
  as S\nimport Control.Concurrent (threadDelay)\n\nmain = S.toList $ parallely $ foldMap
  delay [1..10]\n where delay n = S.yieldM $ threadDelay (n * 1000000) >> print n\n```\n\nStreams
  can be combined together in many ways. We provide some examples\nbelow, see the
  tutorial for more ways. We use the following `delay`\nfunction in the examples to
  demonstrate the concurrency aspects:\n\n``` haskell\nimport Streamly\nimport qualified
  Streamly.Prelude as S\nimport Control.Concurrent\n\ndelay n = S.yieldM $ do\n    threadDelay
  (n * 1000000)\n    tid <- myThreadId\n    putStrLn (show tid ++ \": Delay \" ++
  show n)\n```\n### Serial\n\n``` haskell\nmain = runStream $ delay 3 <> delay 2 <>
  delay 1\n```\n```\nThreadId 36: Delay 3\nThreadId 36: Delay 2\nThreadId 36: Delay
  1\n```\n\n### Parallel\n\n``` haskell\nmain = runStream . parallely $ delay 3 <>
  delay 2 <> delay 1\n```\n```\nThreadId 42: Delay 1\nThreadId 41: Delay 2\nThreadId
  40: Delay 3\n```\n\n## Nested Loops (aka List Transformer)\n\nThe monad instance
  composes like a list monad.\n\n``` haskell\nimport Streamly\nimport qualified Streamly.Prelude
  as S\n\nloops = do\n    x <- S.fromFoldable [1,2]\n    y <- S.fromFoldable [3,4]\n
  \   S.yieldM $ putStrLn $ show (x, y)\n\nmain = runStream loops\n```\n```\n(1,3)\n(1,4)\n(2,3)\n(2,4)\n```\n\n##
  Concurrent Nested Loops\n\nTo run the above code with, lookahead style concurrency
  i.e. each iteration in\nthe loop can run run concurrently by but the results are
  presented in the same\norder as serial execution:\n\n``` haskell\nmain = runStream
  $ aheadly $ loops\n```\n\nTo run it with depth first concurrency yielding results
  asynchronously in the\nsame order as they become available (deep async composition):\n\n```
  haskell\nmain = runStream $ asyncly $ loops\n```\n\nTo run it with breadth first
  concurrency and yeilding results asynchronously\n(wide async composition):\n\n```
  haskell\nmain = runStream $ wAsyncly $ loops\n```\n\nThe above streams provide lazy/demand-driven
  concurrency which is automatically\nscaled as per demand and is controlled/bounded
  so that it can be used on\ninfinite streams. The following combinator provides strict,
  unbounded\nconcurrency irrespective of demand:\n\n``` haskell\nmain = runStream
  $ parallely $ loops\n```\n\nTo run it serially but interleaving the outer and inner
  loop iterations\n(breadth first serial):\n\n``` haskell\nmain = runStream $ wSerially
  $ loops\n```\n\n## Magical Concurrency\n\nStreams can perform semigroup (<>) and
  monadic bind (>>=) operations\nconcurrently using combinators like `asyncly`, `parallelly`.
  For example,\nto concurrently generate squares of a stream of numbers and then concurrently\nsum
  the square roots of all combinations of two streams:\n\n``` haskell\nimport Streamly\nimport
  qualified Streamly.Prelude as S\n\nmain = do\n    s <- S.sum $ asyncly $ do\n        --
  Each square is performed concurrently, (<>) is concurrent\n        x2 <- foldMap
  (\\x -> return $ x * x) [1..100]\n        y2 <- foldMap (\\y -> return $ y * y)
  [1..100]\n        -- Each addition is performed concurrently, monadic bind is concurrent\n
  \       return $ sqrt (x2 + y2)\n    print s\n```\n\nThe concurrency facilities
  provided by streamly can be compared with\n[OpenMP](https://en.wikipedia.org/wiki/OpenMP)
  and\n[Cilk](https://en.wikipedia.org/wiki/Cilk) but with a more declarative\nexpression.\n\n##
  Rate Limiting\n\nFor bounded concurrent streams, stream yield rate can be specified.
  For\nexample, to print hello once every second you can simply write this:\n\n```
  haskell\nimport Streamly\nimport Streamly.Prelude as S\n\nmain = runStream $ asyncly
  $ avgRate 1 $ S.repeatM $ putStrLn \"hello\"\n```\n\nFor some practical uses of
  rate control, see\n[AcidRain.hs](https://github.com/composewell/streamly/tree/master/examples/AcidRain.hs)\nand\n[CirclingSquare.hs](https://github.com/composewell/streamly/tree/master/examples/CirclingSquare.hs)\n.\nConcurrency
  of the stream is automatically controlled to match the specified\nrate. Rate control
  works precisely even at throughputs as high as millions of\nyields per second. For
  more sophisticated rate control see the haddock\ndocumentation.\n\n## Exceptions\n\nFrom
  a library user point of view, there is nothing much to learn or talk about\nexceptions.
  \ Synchronous exceptions work just the way they are supposed to work\nin any standard
  non-concurrent code. When concurrent streams are combined\ntogether, exceptions
  from the constituent streams are propagated to the\nconsumer stream. When an exception
  occurs in any of the constituent streams\nother concurrent streams are promptly
  terminated. Exceptions can be thrown\nusing the `MonadThrow` instance.\n\nThere
  is no notion of explicit threads in streamly, therefore, no\nasynchronous exceptions
  to deal with. You can just ignore the zillions of\nblogs, talks, caveats about async
  exceptions. Async exceptions just don't\nexist.  Please don't use things like `myThreadId`
  and `throwTo` just for fun!\n\n\n## Reactive Programming (FRP)\n\nStreamly is a
  foundation for first class reactive programming as well by virtue\nof integrating
  concurrency and streaming. See\n[AcidRain.hs](https://github.com/composewell/streamly/tree/master/examples/AcidRain.hs)\nfor
  a console based FRP game example and\n[CirclingSquare.hs](https://github.com/composewell/streamly/tree/master/examples/CirclingSquare.hs)\nfor
  an SDL based animation example.\n\n## Conclusion\n\nStreamly, short for streaming
  concurrently, provides monadic streams, with a\nsimple API, almost identical to
  standard lists, and an in-built\nsupport for concurrency.  By using stream-style
  combinators on stream\ncomposition, streams can be generated, merged, chained, mapped,
  zipped, and\nconsumed concurrently – providing a generalized high level programming\nframework
  unifying streaming and concurrency. Controlled concurrency allows\neven infinite
  streams to be evaluated concurrently.  Concurrency is auto scaled\nbased on feedback
  from the stream consumer.  The programmer does not have to be\naware of threads,
  locking or synchronization to write scalable concurrent\nprograms.\n\nStreamly is
  a programmer first library, designed to be useful and friendly to\nprogrammers for
  solving practical problems in a simple and concise manner. Some\nkey points in favor
  of streamly are:\n\n  * _Simplicity_: Simple list like streaming API, if you know
  how to use lists\n    then you know how to use streamly. This library is built with
  simplicity\n    and ease of use as a design goal.\n  * _Concurrency_: Simple, powerful,
  and scalable concurrency.  Concurrency is\n    built-in, and not intrusive, concurrent
  programs are written exactly the\n    same way as non-concurrent ones.\n  * _Generality_:
  Unifies functionality provided by several disparate packages\n    (streaming, concurrency,
  list transformer, logic programming, reactive\n    programming) in a concise API.\n
  \ * _Performance_: Streamly is designed for high performance. It employs stream\n
  \   fusion optimizations for best possible performance. Serial peformance is\n    equivalent
  to the venerable `vector` library in most cases and even better\n    in some cases.
  \ Concurrent performance is unbeatable.  See\n    [streaming-benchmarks](https://github.com/composewell/streaming-benchmarks)\n
  \   for a comparison of popular streaming libraries on micro-benchmarks.\n\nThe
  basic streaming functionality of streamly is equivalent to that provided by\nstreaming
  libraries like\n[vector](https://hackage.haskell.org/package/vector),\n[streaming](https://hackage.haskell.org/package/streaming),\n[pipes](https://hackage.haskell.org/package/pipes),
  and\n[conduit](https://hackage.haskell.org/package/conduit).\nIn addition to providing
  streaming functionality, streamly subsumes\nthe functionality of list transformer
  libraries like `pipes` or\n[list-t](https://hackage.haskell.org/package/list-t),
  and also the logic\nprogramming library [logict](https://hackage.haskell.org/package/logict).
  On\nthe concurrency side, it subsumes the functionality of the\n[async](https://hackage.haskell.org/package/async)
  package, and provides even\nhigher level concurrent composition. Because it supports\nstreaming
  with concurrency we can write FRP applications similar in concept to\n[Yampa](https://hackage.haskell.org/package/Yampa)
  or\n[reflex](https://hackage.haskell.org/package/reflex).\n\nSee the `Comparison
  with existing packages` section at the end of the\n[tutorial](https://hackage.haskell.org/package/streamly/docs/Streamly-Tutorial.html).\n\n##
  Further Reading\n\nFor more information, see:\n\n  * [Detailed tutorial](https://hackage.haskell.org/package/streamly/docs/Streamly-Tutorial.html)\n
  \ * [Reference documentation](https://hackage.haskell.org/package/streamly)\n  *
  [Examples](https://github.com/composewell/streamly/tree/master/examples)\n  * [Guides](https://github.com/composewell/streamly/blob/master/docs)\n
  \ * [Streaming benchmarks](https://github.com/composewell/streaming-benchmarks)\n
  \ * [Concurrency benchmarks](https://github.com/composewell/concurrency-benchmarks)\n\n##
  Support\n\nIf you require professional support, consulting, training or timely\nenhancements
  to the library please contact\n[support@composewell.com](mailto:support@composewell.com).\n\n##
  Contributing\n\nThe code is available under BSD-3 license\n[on github](https://github.com/composewell/streamly).
  Join the\n[gitter chat](https://gitter.im/composewell/streamly) channel for discussions.\nYou
  can find some of the\n[todo items on the github wiki](https://github.com/composewell/streamly/wiki/Things-To-Do).\nPlease
  ask on the gitter channel or [contact the maintainer directly](mailto:harendra.kumar@gmail.com)\nfor
  more details on each item. All contributions are welcome!\n\nThis library was originally
  inspired by the `transient` package authored by\nAlberto G. Corona.\n"
license-name: BSD-3-Clause
