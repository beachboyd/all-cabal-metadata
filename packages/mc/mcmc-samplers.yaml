homepage: ''
changelog-type: ''
hash: c42f994480337113cdecd4f7a515dda4654a358a2b86c4b6e558d5ae602537d9
test-bench-deps: {}
maintainer: pravnar@indiana.edu
synopsis: Combinators for MCMC sampling
changelog: ''
basic-deps:
  hakaru: ==0.1.4
  mwc-random: ! '>=0.13 && <0.14'
  base: ! '>=4.6 && <5'
  containers: ! '>=0.5 && <0.6'
  statistics: ! '>=0.11'
  hmatrix: ! '>=0.15'
  primitive: ! '>=0.5 && <0.6'
all-versions:
- 0.1.0.0
- 0.1.1.0
- 0.1.1.1
author: Praveen Narayanan
latest: 0.1.1.1
description-type: markdown
description: ! "Samplers\n========\n\n### Here lies a library of combinators for MCMC
  kernels and proposals\n- The relevant modules are `Kernels`, `Distributions`, and
  `Actions`\n- See `Tests.hs` for some examples on how this library can be used\n-
  Needs the [hmatrix](http://hackage.haskell.org/package/hmatrix) package\n  - Might
  need to do `cabal install hmatrix`\n\n##### On Gibbs.hs\n\n- The current implementation
  is for a Naive Bayes model\n- TODO:\n  - Use an existing, \"real\" dataset instead
  of randomly generating sentences\n  - See which words appear most frequently for
  each label/class\n  - Average over all theta estimates and return top 10 and bottom
  10 words\n\taccording to these averages\n  - Implement burn-in and lag (to decrease
  autocorrelation)\n"
license-name: BSD-3-Clause
