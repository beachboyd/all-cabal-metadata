homepage: https://github.com/k-bx/protocol-buffers
changelog-type: ''
hash: a76233912cdb863f4746f4c64f452a7990e36c5b7b3c21ccbdfdf2cdf1a26171
test-bench-deps: {}
maintainer: Timo von Holtz <tvh@tvholtz.de>, Kostiantyn Rybnikov <k-bx@k-bx.com>
synopsis: Parse Google Protocol Buffer specifications
changelog: ''
basic-deps:
  bytestring: -any
  base: ! '>=4.7.0 && <5'
  syb: -any
  filepath: -any
  parsec: -any
  array: -any
  containers: -any
  binary: -any
  utf8-string: -any
  mtl: -any
  directory: -any
all-versions:
- '0.0.1'
- '0.0.2'
- '0.0.5'
- '0.1.0'
- '0.2.8'
- '0.2.9'
- '0.3.1'
- '1.0.0'
- '1.0.1'
- '1.2.1'
- '1.2.2'
- '1.4.0'
- '1.5.0'
- '1.6.0'
- '1.7.9'
- '1.8.0'
- '1.8.2'
- '1.8.3'
- '2.0.0'
- '2.0.2'
- '2.0.5'
- '2.0.6'
- '2.0.7'
- '2.0.8'
- '2.0.9'
- '2.0.10'
- '2.0.11'
- '2.0.12'
- '2.0.14'
- '2.0.17'
- '2.1.0'
- '2.1.1'
- '2.1.2'
- '2.1.3'
- '2.1.4'
- '2.1.5'
- '2.1.6'
- '2.1.7'
- '2.1.8'
- '2.1.9'
- '2.1.10'
- '2.1.11'
- '2.1.12'
- '2.2.0'
- '2.3.0'
- '2.3.1'
- '2.4.0'
- '2.4.1'
- '2.4.2'
- '2.4.3'
- '2.4.4'
- '2.4.5'
- '2.4.6'
- '2.4.7'
- '2.4.8'
- '2.4.9'
- '2.4.10'
- '2.4.11'
author: Christopher Edward Kuklewicz
latest: '2.4.11'
description-type: markdown
description: ! "[![Build Status](https://travis-ci.org/k-bx/protocol-buffers.svg)](https://travis-ci.org/k-bx/protocol-buffers)
  Haskell Protocol Buffers\n====================================================\n\nThis
  the README file for `protocol-buffers`,\n`protocol-buffers-descriptors`, and `hprotoc`.
  These are three\ninterdependent Haskell packages originally written by Chris Kuklewicz.\n\nCurrently,
  maintainership was taken by Timo von Holtz. It is\nplanned to only support GHC 7.10
  and newer unless someone explicitly\nasks for support of earlier versions.\n\n(Needs
  check) This README was updated most recently to reflect version\n`2.0.7`. This code
  should be compatible with Google protobuf version\n`2.3.0`. Changes to keep up with
  Google protobuf version `2.4.0` are\nbeing considered.\n\nWhat is this for? What
  does it do? Why?\n---------------------------------------\n\nIt is a pure Haskell
  re-implementation of the Google code at\nhttps://developers.google.com/protocol-buffers/docs/overview
  which is\n\"...a language-neutral, platform-neutral, extensible way of\nserializing
  structured data for use in communications protocols, data\nstorage, and more.\"
  \ Google's project produces C++, Java, and Python\ncode.  This one produces Haskell
  code.\n\nHow well does this Haskell package duplicate Google's project?\n--------------------------------------------------------------\n\n-
  This provides non-mutable messages that ought to be wire-compatible\n  with Google.\n\n-
  These messages support extensions.\n\n- These messages support unknown fields if
  hprotoc is passed the\n  proper flag (-u or --unknown_fields).\n\n- This does not
  generate anything for Services/Methods.\n\n- Adding support for services has not
  been considered.\n\nI think that Google's code checks for some policy violations
  that are\nnot well documented enough for me to reverse engineer. Some (all?) of\nGoogle's
  APIs include the possibility of mutable messages. I suspect\nthat my message reflection
  is not as useful at runtime as in some of\nGoogle's APIs.\n\nWhat is protocol-buffers?\n-------------------------\n\nThe
  protocol-buffers part is the main library which has two faces:\n\n1. It provides
  an external API exported by module\n`Text.ProtocolBuffers` for users to read and
  write the binary format\nand manipulate the message data structures created by hprotoc.\n\n2.
  It provides an internal API for the messages under module\n`Text.ProtocolBuffers.Header`
  to implement their tasks.\n\nWhat is protocol-buffers-descriptor?\n------------------------------------\n\n-
  It uses the `protocol-buffers` package.\n\n- It provides the code generated by hprotoc
  from `descriptor.proto`\nunder module `Text.DescriptorProtos`.\n\n- This supports
  hprotoc which is used to describe proto files and the\ncode they will generate.\n\n-
  It provides `Text.DescriptorProtos.Options` which help in looking up\nthe new style
  custom options.\n\nWhat is hprotoc?\n----------------\n\n- It uses `protocol-buffers`
  and `protocol-buffers-descriptor` above.\n\n- It is a command line tool that reads
  in `.proto` files and produces\n  Haskell source trees like Google's protoc.\n\n-
  ...and it contains a very nice lexer and parser for the `.proto`\n  file...\n\nThe
  hprotoc part is a executable program which reads `.proto` files\nand uses the `protocol-buffers`
  package to produce a tree of Haskell\nsource files.  The program is called `hprotoc`.
  \ Usage is given by the\nprogram itself, the options themselves are processed in
  order.  It can\ntake several input search paths, and allow an additional module\nprefix,
  a selectable output directory, and ends with a list of of\nproto file to generate
  from.\n\nThe output has to be a tree of modules since each message is given its\nown
  namespace, and a module is the only partitioning of namespace in\nHaskell.  The
  keys for extension fields are defined alongside the\nmessage whose namespace they
  share.  Since message names are both a\ndata type and a namespace the filename and
  the message name match\n(aside from the .hs file extension).\n\nAnd what are the
  examples and tests sub-directories?\n----------------------------------------------------\n\nThe
  examples sub-directory is for duplicating the `addressbook.proto`\nexample that
  Google has with its code.  The `ABF` and `ABF2` file are\nincluded as binary addressbooks.
  \ These can be read by the C++\nexamples from Google, and vice-versa.\n\nThe `tests`
  sub-directory is where I have written some test code to\ndrive the `UnittestProto`
  code generated from Google's\n`unittest.proto` (and `unittest_import.proto`) files.
  \ The `patchBoot`\nfile has the needed file patches to fix up the recursive imports
  (no\nlonger needed!).\n\nWhat do I need to compile the code?\n-----------------------------------\n\n1.
  Install [Haskell Stack Tool](https://github.com/commercialhaskell/stack/)\n2. Run
  `stack build`\n\nAlternatively, go with old-fashioned `cabal build`.\n\nHow mature
  is this code?\n------------------------\n\nIt can write the wire encoding and read
  it back.  It has been tested\nfor interoperability against Google's read/write code
  with\n`addressbook.proto`.\n\n`hprotoc` generates and uses the `Text.DescriptorProtos`
  tree from\nGoogle `descriptor.proto` file.\n\n`hprotoc` has generated code from
  `Google/protobuf/unittest.proto` and\n`Google/protobuf.unittest_import`. These compile
  after adding hs-boot\nfiles `TestAllExtensions.hs-boot`, `TestFieldOrderings.hs-boot`,
  and\n`TestMutualRecursionA.hs-boot` to resolve mutual recursion. The\n`TestEnumWithDupValue`
  has duplicated values which cause a compilation\nwarning.\n\nThere has been QuickCheck
  tests done for\n`UnittestProto/TestAllType.hs` and\n`UnittestProto/TestAllExtensions.hs`
  in the tests subdirectory. These\npass as of `2008-09-19` for version `0.2.7`. These
  test that random\nmessages can be roundtripped to the wire format without changing
  â€”\nwith the caveat that the new extension keys are read back as raw bytes\nbut compare
  equal because of the parsing done by (==).\n\nMutual recursion is a problem?\n------------------------------\n\nNot
  using ghc.  The haskell-src-exts let me generate code with `{-#\nSOURCE #-}` annotated
  imports.  And `hprotoc` generates the needed\nhs-boot files for ghc.  And key import
  cycles are broken by creating\n`Key.hs` files, which users can ignore.\n\nHow stable
  is the API?\n----------------------\n\nThis is the first working release of the
  code.  I do not promise to\nkeep any of the API but I am lazy so most things will
  not change. The\nreflection capabilities may get improved/altered. Stricter warnings\nand
  error detection may be added.  Code will move between\nprotocol-buffers and hprotoc
  projects.  The internals of reading from\nthe wire may be improved.\n\nWhere is
  the API documentation?\n-------------------------------\n\nGenerate haddock with
  `stack haddock` command.\n\nYou can also view API documentation online at\n[Hackage
  page](https://hackage.haskell.org/package/protocol-buffers).\n\nThe imports of `Text.ProtocolBuffers`
  are the public API. The\ngenerated code's API is `Text.ProtocolBuffers.Header`.
  The only usage\nexamples are in the `examples` sub-directory and the `tests`\nsub-directory.
  Since the messages are simply Haskell data types most\nof the manipulation should
  be easy.\n\nThe main thing that is weird is that messages with extension ranges\nget
  an ExtField record field that holds ... an internal data\nstructure.  This is currently
  a `Map` from field number to a rather\ncomplicated existential + GADT combination
  that should really only be\ntouched by the `ExtKey` and `MessageAPI` type class
  methods. The\n`ExtField` data constructor is not hidden, though it could be and\nprobably
  ought to be.\n\nNote that extension fields are inherently slower, especially in
  ghci\n(though ghc's `-O2` helps quite a bit).\n\nThe entire proto file is stored
  in the top level module in\nwire-encoded form and can be accessed as a `FileDescriptorProto`.
  The\nHaskell code also defines its own reflection data types, with one\nstored in
  each generated module and also in a master data type in the\ntop level module (via
  `Show` and `Read`).\n\nWho reads this far?\n-------------------\n\nI suspect no
  one ever will.\n\nWhy define your own Haskell reflection types in addition to\n`FileDescriptorProto`s
  types?\n\nThis allows for the protocol-buffers library package to not depend on\na
  single thing defined in the `protocol-buffers-descriptor` package.\nThis lack of
  recursion made for much simpler bootstrapping and allows\nthe `descriptor.proto`
  generated files to be build separately.\n\nWhile `descriptor.proto` files are a
  great fit as output from parsing\na proto file they are not as good a fit for code
  generation. They mix\nfields and extension keys, they have all optional fields even
  though\nsome things (especially names) are compulsory. They obscure which\ndescriptors
  are groups. They have a nested structure which is useful\nwhen resolving the names
  but not for iterating over for code\ngeneration.\n\nWhat are the pieces of protocol-buffers
  doing?\n----------------------------------------------\n\n- `Basic.hs` defines the
  core data types (that are not already in\n  `Prelude`) and many classes.\n- `Mergeable.hs`
  defines the standard instances of `Mergeable` for\n  combining types.\n- `Default.hs`
  defines the standard default of the basic data types.\n- `Reflections.hs` defines
  the Haskell reflection data types (stored\n  with each generated module).\n- `Get.hs`
  is here because I needed a slightly different style of\n  binary `Get` monad (see
  binary and binary-strict packages). This is\n  standalone and could be put into
  any project. It has long comments\n  inside.\n- `WireMessage.hs` defines 3 things:\n
  \ 1. The Wire instances for the basic data types\n  2. The API for the generated
  module to use to define their own Wire\n     instances\n  3. The API for the user
  to load and save messages This file would\n     not compile with ghc-6.8.3 on a
  G4 (Mac OS X 10.5.4, XCode 3.1)\n     without -fvia-C as the cabal file states.\n-
  `Extensions.hs` is rather large because it add everything needed for\n  extension
  fields (see haddock API docs).  It should not export\n  ExtField's constructor,
  but it currently does.\n- `Header.hs` re-exports what is needed for the instance
  messages.\n- `ProtocolBuffer.hs` re-exports what is needed for the user API.\n\nWhat
  are the pieces of hprotoc doing?\n-------------------------------------\n\n`alex`
  uses `Lexer.x` to generated `Lexer.hs` which slices up the\n`.proto` file into tokens.
  \ The `.proto` layout is well designed,\nquite unambiguous, and easy to tokenize.
  \ The lexer also does the jobs\nof decoding the backslash escape codes in quotes
  strings, and\ninterpreting floating point numbers. Errors and unexpected input are\ninserted
  into the token list, with at least line number level\nprecision.\n\nThe `Parser.hs`
  file has a `Parsec` parser which are really used as\nnested parsers (allowing for
  the type of the user state to change).\nThe `.proto` grammar is well designed and
  the system never needs to\nbacktrack over tokens. The default values and options'
  values parsed\naccording to the expected type, and string default are check for
  valid\nutf8 encoding.  (This also import the `Instances.hs` file)\n\nThe `Resolve.hs`
  has code to resolve all the names to a fully\nqualified form, including name mangling
  where necessary. This includes\ncode to load and parse all the imported `.proto`
  files, reusing parses\nfor efficiency, and detecting import loops. The context built
  from\neach imported file is combined to change the `FileDescriptorProto`\ninto a
  modified `FileDescriptorProto`. This stage also determines that\nextension keys
  are in a valid extensions range declaration, and enum\ndefault values exists.\n\nThe
  `MakeReflections.hs` file converts the nested `FileDescriptorProto`\ninto a flatter
  Haskell reflection data structure. This includes\nparsing the default value stored
  in the `FileDescriptorProto`.\n\nThe `BreakRecursion.hs` file builds graphs describing
  the imports and\nworks out whether and how to create hs-boot and `Key.hs` files
  to allow\nallow for warning-free compilation with ghc (as of 6.10.1).\n\nThe `Gen.hs`
  file takes a Haskell data structure from\n`MakeReflections` and builds a module
  syntax data structure.  The\nsyntax data is quite verbose and several helper functions
  are used to\nhelp with the composition.  The result is easy to print as a string
  to\na file.\n\nThe `ProtoCompile.hs` file is the Main module which defines the\ncommand
  line program `hprotoc`.  This manages most of the interaction\nwith the file system
  (aside from import loading in Resolve).\nEverything that is needed is collected
  into the Options data type\nwhich is passed to \"run\". The output style can be
  tweaked by changing\n\"style\" and \"myMode\".\n\nNew oneof implementation\n------------------------\n\nSince
  `protocol-buffers` version 2.6, the upstream `protocol-buffers`\nsupports [oneof](https://developers.google.com/protocol-buffers/docs/proto?hl=en#oneof)\nkeyword,
  which is a union of different data types.\nIt is very natural to combine the oneof
  specification into Haskell\nADT, so we implement the feature.\n\nIn `hprotoc/oneoftest`,
  we have an example for this. `school.proto` defines\na collection of members in
  a school, which is organized into dormitories.\nEach member should have common attributes
  like `id` and `name`, but there are\nattributes only specific to students, faculties
  or administrators.\n\nTherefore, we define property as a oneof field which is one
  of student, faculty\nand admin type. How it is defined should be easily understood
  from `school.proto`.\n\nOnce `protocol-buffers` is installed, using `hprotoc`, we
  can generate Haskell\nsource codes. Assuming we run `hprotoc` on the `oneoftest`
  directory and generate\nsource code in `hs` directory:\n\n```\noneoftest> hprotoc
  --proto_path=. --haskell_out=hs school.proto\n```\n\nWe will have `School.Member`
  module which defines `Member` by\n(I omit qualifier and strictness annotation here.)\n```\ndata
  Member = Member { id :: Int32\n                     , name :: Utf8\n                     ,
  property :: Maybe Property\n                     }\n```\nand `School.Member.Property`
  module defines `Property` (as `oneof`) by\n```\ndata Property = Prop_student {prop_student
  :: Student }\n              | Prop_faculty {prop_faculty :: Faculty }\n              |
  Prop_admin   {prop_admin   :: Admin   }\n```\nwhere `Student`, `Faculty` and `Admin`
  are defined as ordinary nested message\ndata types in separate modules, respectively.
  Therefore, the `oneof` feature\nis smoothly matched with Haskell sum types. Note
  that `Maybe` will be always\npresent for a `oneof` field in the owner data type
  definition (Here, `Maybe Property`\nin the definition of `Member`). This is because
  of compatibility with other language\nimplementations that treat `oneof` as a collection
  of `optional` fields.\n\nIn the `oneoftest` directory, we provides a Haskell example
  in `hprotoc/oneoftest/hs`,\nmodification of the previous example using lenses in
  `hprotoc/oneoftest/hs-lens`\nand a C++ example in `hprotoc/oneoftest/cpp` to demonstrate
  how to use. Each example\nhas `encode` and `decode`. With `encode`, we start from
  data in memory and generate\na serialized binary file in wire format. Then,`decode`
  takes the file and present\nsome information to prove it successfully decoded the
  binary. One can encode from\nHaskell side and decode on C++ side, or vice versa.
  For building, simply run\n`build.sh` in each of `hs` or `cpp` directories. Example
  with lenses has a `stack.yml`\nin it so it could be easily built with `stack build`.
  For C++, one must previously\ninstall C++ `protobuf` library and `pkg-config`. We
  assume that `hprotoc` was already\nexecuted as shown above. The version with lenses
  requires slightly different command:\n\n```\noneoftest> hprotoc --proto_path=. --haskell_out=hs-lens/src
  school.proto\n```\n\nHere are examples.\n```\nhs >   ./encode serialized.dat\nhs
  >   cd ../cpp\ncpp>   ./decode ../hs/serialized.dat\nname: \"Gryffindor\"\nmembers
  {\n  id: 1\n  name: \"Albus Dumbledore\"\n  prop_faculty {\n    subject: \"allmighty\"\n
  \   title: \"headmaster\"\n  }\n}\nmembers {\n  id: 2\n  name: \"Harry Potter\"\n
  \ prop_student {\n    grade: 5\n    specialty: \"defense of dark arts\"\n  }\n}\n```\n\n```\ncpp>
  \  ./encode serialized.dat\ncpp>   cd ../hs\nhs >   ./decode ../cpp/serialized.dat\n\nRight
  (Dormitory {name = \"Gryffindor\", members = fromList [Member {id = 1, name = \"Albus
  Dumbledore\", property = Just (Prop_faculty {prop_faculty = Faculty {subject = \"allmighty\",
  title = Just \"headmaster\", duty = fromList []}})},Member {id = 2, name = \"Harry
  Potter\", property = Just (Prop_student {prop_student = Student {grade = 5, specialty
  = Just \"defense of dark arts\"}})}]},\"\")\n```\n"
license-name: BSD3
