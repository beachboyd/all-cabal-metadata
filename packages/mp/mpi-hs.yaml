homepage: https://github.com/eschnett/mpi-hs#readme
changelog-type: ''
hash: b1c2debe7a3e384a945cd89313b12d5b57827ddf4ba47083f6885e978c0d33e5
test-bench-deps:
  base: -any
  monad-loops: -any
  criterion: -any
  mpi-hs: -any
maintainer: Erik Schnetter <schnetter@gmail.com>
synopsis: MPI bindings for Haskell
changelog: ''
basic-deps:
  bytestring: -any
  base: ==4.*
  monad-loops: -any
  store: -any
  mpi-hs: -any
all-versions:
- '0.1.0.1'
- '0.3.0.0'
- '0.3.1.0'
author: Erik Schnetter <schnetter@gmail.com>
latest: '0.3.1.0'
description-type: markdown
description: ! "# [mpi-hs](https://github.com/eschnett/mpi-hs)\n\n[MPI](https://www.mpi-forum.org)
  bindings for Haskell\n\n* [<img alt=\"Github\" src=\"share/GitHub_Logo.png\" height=\"25\"\n
  \ align=\"middle\">](https://github.com/eschnett/mpi-hs)\n* [[Hackage]](http://hackage.haskell.org/package/mpi-hs)
  Haskell\n  package and documentation\n* [![CircleCI](https://circleci.com/gh/eschnett/mpi-hs.svg?style=svg)](https://circleci.com/gh/eschnett/mpi-hs)\n\n\n\n##
  Overview\n\nMPI (the Message Passing Interface) is widely used standard for\ndistributed-memory
  programming on HPC (High Performance Computing)\nsystems. MPI allows exchanging
  data (_messages_) between programs\nrunning in parallel. There are several high-quality
  open source MPI\nimplementations (e.g. MPICH, MVAPICH, OpenMPI) as well as a variety
  of\nclosed-source implementations. These libraries can typically make use\nof high-bandwidth
  low-latency communication hardware such as\nInfiniBand.\n\nThis library `mpi-hs`
  provides Haskell bindings for MPI. It is based\non ideas taken from\n[haskell-mpi](https://github.com/bjpop/haskell-mpi),\n[Boost.MPI](https://www.boost.org/doc/libs/1_64_0/doc/html/mpi.html),\nand
  [MPI for Python](https://mpi4py.readthedocs.io/en/stable/).\n\n`mpi-hs` provides
  two API levels: A low-level API gives rather direct\naccess to the MPI API, apart
  from certain \"reasonable\" mappings from C\nto Haskell (e.g. output arguments that
  are in C stored to a pointer\nare in Haskell regular return values). A high-level
  API simplifies\nexchanging arbitrary values that can be serialized.\n\n\n\n## Example\n\nThis
  is a typical MPI C code:\n```C\n#include <stdio.h>\n#include <mpi.h>\n\nint main(int
  argc, char** argv) {\n  MPI_Init(&argc, &argv);\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD,
  &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  printf(\"This is process %d
  of %d\\n\", rank, size);\n  MPI_Finalize();\n  return 0;\n}\n```\n\nThe Haskell
  equivalent looks like this:\n```Haskell\nimport Control.Distributed.MPI as MPI\n\nmain
  :: IO ()\nmain =\n  do MPI.init\n     rank <- MPI.commRank MPI.commWorld\n     size
  <- MPI.commSize MPI.commWorld\n     putStrLn $ \"This is process \" ++ show rank
  ++ \" of \" ++ show size\n     MPI.finalize\n```\n\n\n\n## Installing\n\n`mpi-hs`
  requires an external MPI library to be available on the\nsystem. How to install
  such a library is beyond the scope of these\ninstructions.\n\n<!---\n(It is important
  that the MPI library's include files, libraries, and\nexecutables are installed
  consistently. A common source of problems is\nthat there are several MPI implementations
  available on a system, and\nthat the default include file `mpi.h`, the library `libmpi.a`,
  and/or\nthe executable `mpirun` are provided by different implementations.\nThis
  will lead to various problems, often segfaults, since neither the\noperating system
  nor these libraries provide any protection against\nsuch a mismatch.)\n-->\n\nIn
  many cases, the MPI library will be installed in `/usr/include`,\n`/usr/lib`, and
  `/usr/bin`, respectively. In this case, no further\nconfiguration is necessary,
  and `mpi-hs` will build out of the box\nwith `stack build`.\n\nOn Ubuntu, one MPI
  package is `openmpi-dev`. It installs into\n`/usr/lib/openmpi/include`, `/usr/lib/openmpi/lib`,
  and `/usr/bin/`.\nYou need to ensure that these settings are present in `stack.yaml`:\n\n```yaml\nextra-include-dirs:\n
  \ - /usr/lib/openmpi/include\nextra-lib-dirs:\n  - /usr/lib/openmpi/lib\n```\n\nOn
  MacOS, one MPI package is the [MacPorts](https://www.macports.org)\npackage `openmpi`.
  It installs into `/opt/local/include/openmpi-mp`,\n`/opt/local/lib/openmpi-mp`,
  and `/opt/local/bin`. You need to ensure\nthat these settings are present in `stack.yaml`:\n\n```yaml\nextra-include-dirs:\n
  \ - /opt/local/include/openmpi-mp\nextra-lib-dirs:\n  - /opt/local/lib/openmpi-mp\n```\n\nBoth
  these settings are there by default.\n\n### Testing the MPI installation\n\nTo test
  your MPI installation independently of using Haskell, copy the\nexample MPI C code
  into a file `mpi-example.c`, and run these commands:\n\n```sh\ncc -I/usr/lib/openmpi/include
  -c mpi-example.c\ncc -o mpi-example mpi-example.o -L/usr/lib/openmpi/lib -lmpi\nmpirun
  -np 3 ./mpi-example\n```\n\nAll three commands must complete without error, and
  the last command\nmust output something like\n\n```\nThis is process 0 of 3\nThis
  is process 1 of 3\nThis is process 2 of 3\n```\n\nwhere the order in which the lines
  are printed can be random. (The\noutput might even be jumbled, i.e. the characters
  of the three lines\nmight be mixed up.)\n\nIf these commands do not work, then this
  needs to be corrected before\n`mpi-hs` can work. If additional compiler options
  or libraries are\nneeded, then these need to be added to the `stack.yaml` configuration\nfile
  (for include and library paths; see `extra-include-dirs` and\n`extra-lib-dirs` there)
  or the `package.yaml` configuration file (for\nadditional libraries; see `extra-libraries`
  there).\n"
license-name: Apache-2.0
