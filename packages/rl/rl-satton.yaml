homepage: https://github.com/grwlf/rl
changelog-type: ''
hash: 73a658b99d04036f314697615bece5fd911d51b10f6bd3a33f5f264c7c56c82a
test-bench-deps: {}
maintainer: grrwlf@gmail.com
synopsis: Collection of Reinforcement Learning algorithms
changelog: ''
basic-deps:
  MonadRandom: -any
  mersenne-random-pure64: -any
  stm: -any
  base: ! '>=4.8 && <5'
  time: -any
  unordered-containers: -any
  text: -any
  rl-satton: -any
  monad-loops: -any
  filepath: -any
  process: -any
  parsec: -any
  containers: -any
  lens: -any
  mtl: -any
  hashable: -any
  pretty-show: -any
  transformers: -any
  random: -any
  template-haskell: -any
  directory: -any
all-versions:
- 0.1.0
- 0.1.1
- 0.1.2
- 0.1.2.1
- 0.1.2.2
- 0.1.2.3
- 0.1.2.4
author: Sergey Mironov
latest: 0.1.2.4
description-type: haddock
description: ! 'rl-satton provides implementation of algorithms, described in the

  ''Reinforcement Learing: An Introduction'' book by Richard S. Satton and Andrew

  G. Barto. In particular, TD(0), TD(lambda), Q-learing are implemented.

  Code readability was placed above performance.

  Usage examples are provided in the ./examples folder.'
license-name: BSD-3-Clause
