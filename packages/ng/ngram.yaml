homepage: https://github.com/TomLippincott/ngram#readme
changelog-type: ''
hash: 0c9880feee4d65e9646a5bea9c2a85d12e27116185e6d4aca3210944e97d6dd6
test-bench-deps: {}
maintainer: tom@cs.jhu.edu
synopsis: Ngram models for compressing and classifying text.
changelog: ''
basic-deps:
  cereal-text: ! '>=0.1.0.2'
  cereal: ! '>=0.5.4.0'
  ngram: -any
  bytestring: ! '>=0.10.8.1'
  optparse-generic: ! '>=1.2.2'
  base: ! '>=4.7 && <5'
  text: ! '>=1.2.2'
  containers: ! '>=0.5.10.2'
  zlib: ! '>=0.6.1'
all-versions:
- '0.1.0.0'
author: Tom Lippincott
latest: '0.1.0.0'
description-type: markdown
description: ! "# NGrams\n\nThis is a code base for experimenting with various approaches
  to n-gram-based\ntext modeling.  To get started, run:\n\n```bash\nstack build\nstack
  install\n```\n\nThis will build and install the library and binary commands.  Generally,\nthe
  commands expect data to be text files where each line has the format:\n\n```\n${id}<TAB>${label}<TAB>${text}\n```\n\nWhen
  a model is applied to data, the output will generally have a header\nwith the format:\n\n```\nID<TAB>GOLD<TAB>${label_1_name}<TAB>${label_2_name}<TAB>...\n```\n\nand
  lines with the corresponding format:\n\n```\n${doc_id}<TAB>${gold_label_name}<TAB>${label_1_prob}<TAB>${label_2_prob}<TAB>...\n```\n\nwhere
  probabilities are represented as natural logarithms.\n\nThe remainder of this document
  describes the implemented models, most of which\nhave a corresponding command that
  *stack* will have installed.  The library aims\nto be parametric over the sequence
  types, and most commands allow users to \nspecify whether to consider bytes, unicode
  characters, or whitespace-delimited \ntokens.\n\n## Prediction by Partial Matching\n\nPPM
  is essentially an n-gram model with a particular backoff logic that can't \nquite
  be reduced to more widespread approaches to smoothing, but empirically \ntends to
  outperform them on short documents.  To create a PPM model, run:\n\n```bash\nsh>
  ppm train --train train.txt --dev dev.txt --n 4 --modelFile model.gz\nDev accuracy:
  0.8566666666666667\n```\n\nThe model can then be applied to new data:\n\n```bash\nsh>
  ppm apply --test test.txt --modelFile model.gz --n 4 --scoresFile scores.txt\n```\n\nThe
  value of `--n` can also be less than the model size, which will run a bit \nfaster,
  and (perhaps) less tuned to the original training data.\n"
license-name: BSD3
