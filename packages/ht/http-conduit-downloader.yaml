homepage: https://github.com/bazqux/http-conduit-downloader
changelog-type: ''
hash: 8a0ce607bc075ff3a1d46a2dd70b26bae5d36104e806aa93fd8e2f12d10611f3
test-bench-deps: {}
maintainer: Vladimir Shabanov <vshabanoff@gmail.com>
synopsis: HTTP downloader tailored for web-crawler needs.
changelog: ''
basic-deps:
  http-client: ! '>=0.6.1'
  bytestring: -any
  base: ==4.*
  time: ! '>=1.5.0'
  text: -any
  network: ! '>=2.6'
  connection: -any
  conduit: -any
  data-default: -any
  zlib: -any
  network-uri: ! '>=2.6'
  mtl: -any
  http-conduit: ! '>=2.3.4'
  HsOpenSSL: ! '>=0.11.2'
  resourcet: -any
  http-types: -any
all-versions:
- 1.0.0
- 1.0.1
- 1.0.2
- 1.0.3
- 1.0.4
- 1.0.5
- 1.0.6
- 1.0.7
- 1.0.8
- 1.0.9
- 1.0.10
- 1.0.11
- 1.0.12
- 1.0.13
- 1.0.14
- 1.0.15
- 1.0.16
- 1.0.17
- 1.0.18
- 1.0.19
- 1.0.20
- 1.0.21
- 1.0.22
- 1.0.23
- 1.0.24
- 1.0.25
- 1.0.30
- 1.0.31
- 1.0.32
- 1.0.33
author: Vladimir Shabanov <vshabanoff@gmail.com>
latest: 1.0.33
description-type: haddock
description: |-
  HTTP/HTTPS downloader built on top of @http-conduit@
  and used in <https://bazqux.com> crawler.

  * Handles all possible http-conduit exceptions and returns
  human readable error messages.

  * Handles some web server bugs (returning 'deflate' data instead of 'gzip',
  invalid 'gzip' encoding).

  * Uses OpenSSL instead of 'tls' package (since 'tls' doesn't handle all sites).

  * Ignores invalid SSL sertificates.

  * Receives data in 32k chunks internally to reduce memory fragmentation
  on many parallel downloads.

  * Download timeout.

  * Total download size limit.

  * Returns HTTP headers for subsequent redownloads and handles
  'Not modified' results.

  * Can be used with external DNS resolver (e.g. concurrent-dns-cache).
license-name: BSD-3-Clause
