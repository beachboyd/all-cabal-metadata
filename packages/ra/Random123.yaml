homepage: http://github.com/Manticore/haskell-random123
changelog-type: ''
hash: 179a04fbc3ea8cb5de1f8e3501f643d91a6c1a73fb7b4f60b26761e038f50f3c
test-bench-deps:
  test-framework-hunit: ! '>=0.3'
  test-framework: ! '>=0.8'
  base: ! '>=4.7 && <5.0'
  Random123: -any
  test-framework-quickcheck2: ! '>=0.3'
  criterion: ! '>=1.0'
  HUnit: ! '>=1.2'
  random: ! '>=1.0'
  QuickCheck: ! '>=2.5'
maintainer: Bogdan Opanchuk <bogdan@opanchuk.net>
synopsis: Haskell port of Random123 library
changelog: ''
basic-deps:
  data-dword: -any
  base: ! '>=4.7.0.0 && <5.0'
  array: ! '>=0.4'
  random: ! '>=1.0.0.0'
all-versions:
- 0.1.0
- 0.1.1
- 0.1.2
- 0.2.0
author: Bogdan Opanchuk <bogdan@opanchuk.net>
latest: 0.2.0
description-type: text
description: ! "Random123\n=========\n\nThis is a Haskell port of counter-based random
  number generators from `Random123 library <http://www.thesalmons.org/john/random123/>`_
  v1.07 (with a minor bugfix).\nThe description of algorithms can be also found in
  `Salmon et al., P. Int. C. High. Perform. 16 (2011) <http://dx.doi.org/doi:10.1145/2063384.2063405>`_.\n\n\nContributing\n------------\n\nWhen
  making changes to the library, run (or update, if necessary) functionality tests.\nThis
  can be done as\n\n::\n\n    $ cabal configure --enable-tests\n    $ cabal build\n
  \   $ cabal test\n\nor just by executing ``cd test; ./test.sh``.\nYou can also check
  the performance by running benchmarks as\n\n::\n\n    $ cabal configure --enable-benchmarks\n
  \   $ cabal build\n    $ cabal bench\n\nor by executing ``cd test; ./test_perf.sh``.\nBenchmarks
  will create a report file ``test_perf.html``\nin the folder where they were executed
  from.\n\n\nTODO\n----\n\n* Performance issues:\n\n    * According to Salmon et al.,
  Threefry-4x64 should be the fastest algorithm on CPUs.\n      This is not what I'm
  seeing; need to investigate it further.\n      If it is made faster, it should be
  used as the default bijection for ``CBRNG32/64``\n      instead of ``philox4``.\n\n
  \   * 32-bit Threefry shows suprisingly low performance (see ``Bijection`` benchmark
  group).\n\n    * In general, there seems to be a lot of optimizations that can be
  done,\n      in particular in terms of strategically placed strictness enforcement.\n\n*
  Current ``split`` implementation is a quick solution that kind of works\n  (much
  like ``StdGen``'s one).\n  A mathematically robust implementation is required\n
  \ (and CBRNGs by nature should be well-suited for this).\n  Moreover, it would be
  great to have some tests that could distinguish\n  \"bad\" ``split`` from a \"good\"
  one.\n"
license-name: MIT
