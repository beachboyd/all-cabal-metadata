homepage: https://github.com/ocramz/sparse-linear-algebra
changelog-type: markdown
hash: a108761785de5caa59d4eaab17d1ec3fc785d7ef78a5e3533f5fb479c6384d0f
test-bench-deps:
  exceptions: -any
  mwc-random: -any
  base: -any
  hspec: -any
  vector-space: -any
  containers: -any
  matrix-market-attoparsec: -any
  mtl: ! '>=2.2.1'
  sparse-linear-algebra: -any
  scientific: -any
  QuickCheck: ! '>=2.8.2'
  primitive: ! '>=0.6.1.0'
maintainer: zocca.marco gmail
synopsis: Numerical computation in native Haskell
changelog: ! "\n\t0.2.9.4\n\t-------\n\n\tExceptions constructors are exported by
  Numeric.LinearAlgebra.Sparse\n\n\n\t0.2.9.1\n\n\t-------\n\n\t* Uses classes from
  `vector-space` such as AdditiveGroup, VectorSpace and InnerSpace\n\t* QuickCheck
  tests for algebraic properties, such as matrix-vector products and soon more abstract
  ones e.g. positive semi-definite matrices\n\t* Getting rid of `error` in favor of
  MonadThrow exceptions for high-level operations\nsuch as matrix algorithms\n"
basic-deps:
  exceptions: -any
  base: ! '>=4.7 && <5'
  vector-space: -any
  containers: -any
  mtl: ! '>=2.2.1'
  vector-algorithms: -any
  transformers: -any
  vector: -any
all-versions:
- '0.2.9.4'
- '0.2.9.5'
- '0.2.9.6'
- '0.2.9.7'
author: Marco Zocca
latest: '0.2.9.7'
description-type: markdown
description: ! "# sparse-linear-algebra\n\nNumerical computation in native Haskell\n\n[![Hackage](https://img.shields.io/hackage/v/sparse-linear-algebra.svg)](https://hackage.haskell.org/package/sparse-linear-algebra)
  \ [![Build Status](https://travis-ci.org/ocramz/sparse-linear-algebra.png)](https://travis-ci.org/ocramz/sparse-linear-algebra)\n\nThis
  library provides common numerical analysis functionality, without requiring any
  external bindings. It is not optimized for performance (yet), but it serves as an
  experimental platform for scientific computation in a purely functional setting.\n\nContents
  :\n\n* Iterative linear solvers (`<\\>`)\n\n    * Generalized Minimal Residual (GMRES)
  (non-Hermitian systems) \n\n    * BiConjugate Gradient (BCG)\n\n    * Conjugate
  Gradient Squared (CGS)\n\n    * BiConjugate Gradient Stabilized (BiCGSTAB) (non-Hermitian
  systems)\n\n    * Moore-Penrose pseudoinverse (`pinv`) (rectangular systems)\n\n*
  Direct linear solvers\n\n    * LU-based (`luSolve`); forward and backward substitution
  (`triLowerSolve`, `triUpperSolve`)\n    \n* Matrix factorization algorithms\n\n
  \   * QR (`qr`)\n\n    * LU (`lu`)\n\n    * Cholesky (`chol`)\n\n    * Arnoldi iteration
  (`arnoldi`)\n\n* Eigenvalue algorithms\n\n    * QR (`eigsQR`)\n\n    * QR-Arnoldi
  (`eigsArnoldi`) \n\n\n\n* Utilities : Vector and matrix norms, matrix condition
  number, Givens rotation, Householder reflection\n\n* Predicates : Matrix orthogonality
  test (A^T A ~= I)\n\n\n\n### Under development\n\n* Eigenvalue algorithms\n\n    *
  Rayleigh quotient iteration (`eigRayleigh`)\n\n* Matrix factorization algorithms\n\n
  \   * Golub-Kahan-Lanczos bidiagonalization (`gklBidiag`)\n   \n    * Singular value
  decomposition (SVD)\n\n* Iterative linear solvers\n\n    * Transpose-Free Quasi-Minimal
  Residual (TFQMR)\n\n---------\n\n## Examples\n\nThe module `Numeric.LinearAlgebra.Sparse`
  contains the user interface.\n\n### Creation of sparse data\n\nThe `fromListSM`
  function creates a sparse matrix from a collection of its entries in (row, column,
  value) format. This is its type signature:\n\n    fromListSM :: Foldable t => (Int,
  Int) -> t (IxRow, IxCol, a) -> SpMatrix a\n\nand, in case you have a running GHCi
  session (the terminal is denoted from now on by `λ>`), you can try something like
  this:\n\n    λ> amat = fromListSM (3,3) [(0,0,2),(1,0,4),(1,1,3),(1,2,2),(2,2,5)]
  :: SpMatrix Double\n\nSimilarly, `fromListSV` is used to create sparse vectors:
  \n\n    fromListSV :: Int -> [(Int, a)] -> SpVector a\n    \n\nAlternatively, the
  user can copy the contents of a list to a (dense) SpVector using\n\n    fromListDenseSV
  :: Int -> [a] -> SpVector a\n\n\n\n### Displaying sparse data\n\nBoth sparse vectors
  and matrices can be pretty-printed using `prd`:\n\n    λ> prd amat\n    ( 3 rows,
  3 columns ) , 5 NZ ( sparsity 0.5555555555555556 )\n\n    2.0  _   _ \n    4.0 3.0
  2.0\n     _   _  5.0\n\nNote: sparse data should only contain non-zero entries not
  to waste memory and computation.\n\n### Matrix operations\n\nThere are a few common
  matrix factorizations available; in the following example we compute the LU factorization
  of matrix `amat` and verify it with the matrix-matrix product `##` of its factors
  :\n\n    λ> (l, u) <- lu amat\n    λ> prd $ l ## u\n    ( 3 rows, 3 columns ) ,
  9 NZ ( sparsity 1.0 )\n\n    2.0  _   _ \n    4.0 3.0 2.0\n     _   _  5.0\n\nNotice
  that the result is _dense_, i.e. certain entries are numerically zero but have been
  inserted into the result along with all the others (thus taking up memory!).\nTo
  preserve sparsity, we can use a sparsifying matrix-matrix product `#~#`, which filters
  out all the elements x for which `|x| <= eps`, where `eps` (defined in `Numeric.Eps`)
  depends on the numerical type used (e.g. it is 10^-6 for `Float`s and 10^-12 for
  `Double`s).\n\n    λ> prd $ l #~# u\n    ( 3 rows, 3 columns ) , 5 NZ ( sparsity
  0.5555555555555556 )\n\n    2.0  _   _ \n    4.0 3.0 2.0\n     _   _  5.0    \n\nA
  matrix is transposed using the `transpose` function.\n\nSometimes we need to compute
  matrix-matrix transpose products, which is why the library offers the infix operators
  `#^#` (i.e. matrix transpose * matrix) and `##^` (matrix * matrix transpose):\n\n
  \   λ> amat' = amat #^# amat\n    λ> prd amat'\n    ( 3 rows, 3 columns ) , 9 NZ
  ( sparsity 1.0 )\n\n    20.0 12.0 8.0\n    12.0 9.0 6.0\n    8.0 6.0 29.0\n    \n
  \   λ> l <- chol amat'\n    λ> prd $ l ##^ l\n    ( 3 rows, 3 columns ) , 9 NZ (
  sparsity 1.0 )\n\n    20.000000000000004 12.0 8.0\n    12.0 9.0 10.8\n    8.0 10.8
  29.0\n\nIn the last example we have also shown the Cholesky decomposition (M = L
  L^T where L is a lower-triangular matrix), which is only defined for symmetric positive-definite
  matrices.\n\n### Linear systems\n\nLarge sparse linear systems are best solved with
  iterative methods. `sparse-linear-algebra` provides a selection of these via the
  `<\\>` (inspired by Matlab's \"backslash\" function. Currently this method uses
  GMRES as default) :\n\n    λ> b = fromListDenseSV 3 [3,2,5] :: SpVector Double\n
  \   λ> x <- amat <\\> b\n    λ> prd x\n    ( 3 elements ) ,  3 NZ ( sparsity 1.0
  )\n\n    1.4999999999999998 -1.9999999999999998 0.9999999999999998\n\nThe result
  can be verified by computing the matrix-vector action `amat #> x`, which should
  (ideally) be very close to the right-hand side `b` :\n\n    λ> prd $ amat #> x\n
  \   ( 3 elements ) ,  3 NZ ( sparsity 1.0 )\n\n    2.9999999999999996 1.9999999999999996
  4.999999999999999\n\nThe library also provides a forward-backward substitution solver
  (`luSolve`) based on a triangular factorization of the system matrix (usually LU).
  This should be the preferred for solving smaller, dense systems. Using the data
  defined above we can cross-verify the two solution methods:\n\n    λ> x' <- luSolve
  l u b\n    λ> prd x'\n\n    ( 3 elements ) ,  3 NZ ( sparsity 1.0 )\n\n    1.5 -2.0
  1.0\n\n\n\n\n\n\n\n\n## License\n\nGPL3, see LICENSE\n\n## Credits\n\nInspired by\n\n*
  `linear` : https://hackage.haskell.org/package/linear\n* `vector-space` : https://hackage.haskell.org/package/vector-space\n*
  `sparse-lin-alg` : https://github.com/laughedelic/sparse-lin-alg\n\n## References\n\n[1]
  Y. Saad, Iterative Methods for Sparse Linear Systems, 2nd ed., 2000\n\n[2] G.H.
  Golub and C.F. Van Loan, Matrix Computations, 3rd ed., 1996\n\n[3] L.N. Trefethen,
  D. Bau, Numerical Linear Algebra, SIAM, 1997\n\n[4] W.H. Press, S.A. Teukolsky,
  W.T. Vetterling, B.P. Flannery, Numerical Recipes in Fortran 77, 2nd ed., 1992 "
license-name: GPL-3
