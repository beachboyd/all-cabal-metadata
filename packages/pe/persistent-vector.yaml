homepage: https://github.com/travitch/persistent-vector
changelog-type: ''
hash: cc4ee4ded4aed1753f2807f5db703b1b89d40dc5bcb91f16e82472c1b1a413cc
test-bench-deps:
  test-framework: -any
  base: ==4.*
  test-framework-quickcheck2: -any
  criterion: ! '>=1 && <1.2'
  persistent-vector: -any
  containers: -any
  deepseq: -any
  QuickCheck: ! '>2.4'
maintainer: tristan@nochair.net
synopsis: A persistent sequence based on array mapped tries
changelog: ''
basic-deps:
  base: ==4.*
  deepseq: -any
all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.1.0.3
- 0.1.1
author: Tristan Ravitch
latest: 0.1.1
description-type: markdown
description: ! "# Persistent Vector\n\nA library providing persistent (purely functional)
  vectors for Haskell\nbased on array mapped tries.\n\n## Description\n\nThese persistent
  vectors are modeled on the persistent vector used by\nclojure, with an API modeled
  after Data.Sequence from the containers\nlibrary.  This data structure is *spine
  strict* and is not useful for\nincremental consumption.  If you need that, stick
  to lists.  It is\nstill lazy in the elements.\n\nWhile per-element operations are
  O(log(n)), the internal tree can\nnever be more than 7 or 8 deep.  Thus, they are
  effectively constant\ntime.\n\nThis implementation adds O(1) slicing support for
  vectors that I do\nnot believe clojure supports.  The implementation cheats, though,
  and\nslices can retain references to objects that cannot be indexed.\n\n## Performance\n\nPerformance
  is an important consideration for a data structure like\nthis.  The package contains
  a criterion benchmark suite that attempts\nto compare the performance of persistent
  vectors against a variety of\nexisting persistent data structures.  As an overview
  of the results I\nhave observed:\n\n * Traversing and building lists is faster than
  the same operations\n   with persistent vectors.\n\n * (Strict) left folds over
  persistent vectors are faster than left\n   folds over Sequences.  Right folds over
  Sequences are faster than\n   right folds over vectors.\n\n * Indexing persistent
  vectors is faster than indexing sequences and\n   IntMaps (and, of course, lists).\n\n
  * Appending to vectors is slightly faster than appending to a Sequence.\n   It is
  much faster than appending to an IntMap.\n\n * Updating an element at an index in
  a vector is *slower* than\n   updating an index in a Sequence (but still faster
  than an IntMap).\n\nOverall, it seems like persistent vectors are efficient at most
  tasks.\nIf you only need a (strict) left fold, they are efficient for\ntraversal.
  \ Indexing and construction are very fast, but Sequences are\nsuperior for element-wise
  updates.\n\n## Implementation\n\n## TODO\n\n * More of the Data.Sequence API\n\n
  * More efficient Eq and Ord instances.  This is tricky in the\n   presence of slicing.
  \ There are faster implementations for unsliced\n   inputs.\n\n * Implement something
  to make parallel reductions simple (maybe\n   something like vector-strategies)\n\n
  * Implement cons.  Cons can use the space that is hidden by the\n   offset cheaply.
  \ It can also make a variant of pushTail\n   (pushHead) that allocates fragments
  of preceeding sub-trees.\n   Each cons call will modify the offset of its result
  vector.\n"
license-name: BSD-3-Clause
