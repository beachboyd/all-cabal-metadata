homepage: https://github.com/haskell-works/hw-kafka-client
changelog-type: ''
hash: 0fe109db4383f1926bc1a61bdeca80c236c8232b8e2023d64990e8597510d43e
test-bench-deps:
  either: -any
  bytestring: -any
  base: ! '>=4.6 && <5'
  hspec: -any
  monad-loops: -any
  containers: -any
  bifunctors: -any
  regex-posix: -any
  hw-kafka-client: -any
maintainer: Alexey Raga <alexey.raga@gmail.com>
synopsis: Kafka bindings for Haskell
changelog: ''
basic-deps:
  bytestring: -any
  unix: -any
  base: ! '>=4.6 && <5'
  containers: -any
  bifunctors: -any
  hw-kafka-client: -any
  transformers: -any
  temporary: -any
all-versions:
- '1.0.0'
- '1.1.0'
- '1.1.1'
- '1.1.2'
- '1.1.3'
- '1.1.4'
- '2.0.0'
- '2.0.1'
- '2.0.2'
- '2.0.3'
- '2.0.4'
author: Alexey Raga <alexey.raga@gmail.com>
latest: '2.0.4'
description-type: markdown
description: ! "# hw-kafka-client\n[![CircleCI](https://circleci.com/gh/haskell-works/hw-kafka-client.svg?style=svg&circle-token=5f3ada2650dd600bc0fd4787143024867b2afc4e)](https://circleci.com/gh/haskell-works/hw-kafka-client)\n\nKafka
  bindings for Haskell backed by the\n[librdkafka C module](https://github.com/edenhill/librdkafka).\n\n##
  Credits\nThis project is inspired by [Haskakafka](https://github.com/cosbynator/haskakafka)\nwhich
  unfortunately doesn't seem to be actively maintained.\n\n## Ecosystem\nHaskellWorks
  Kafka ecosystem is described here: https://github.com/haskell-works/hw-kafka\n\n#
  Consumer\nHigh level consumers are supported by `librdkafka` starting from version
  0.9.\nHigh-level consumers provide an abstraction for consuming messages from multiple\npartitions
  and topics. They are also address scalability (up to a number of partitions)\nby
  providing automatic rebalancing functionality. When a new consumer joins a consumer\ngroup
  the set of consumers attempt to \"rebalance\" the load to assign partitions to each
  consumer.\n\n### Example:\n```\n$ stack build --flag hw-kafka-client:examples\n```\n\nor\n\n```\n$
  stack build --exec kafka-client-example --flag hw-kafka-client:examples\n```\n\nA
  working consumer example can be found here: [ConsumerExample.hs](example/ConsumerExample.hs)</br>\nTo
  run an example please compile with the `examples` flag.\n\n```Haskell\nimport Data.Monoid
  ((<>))\nimport Kafka\nimport Kafka.Consumer\n\n-- Global consumer properties\nconsumerProps
  :: ConsumerProperties\nconsumerProps = brokersList [BrokerAddress \"localhost:9092\"]\n
  \            <> groupId (ConsumerGroupId \"consumer_example_group\")\n             <>
  noAutoCommit\n             <> logLevel KafkaLogInfo\n\n-- Subscription to topics\nconsumerSub
  :: Subscription\nconsumerSub = topics [TopicName \"kafka-client-example-topic\"]\n
  \          <> offsetReset Earliest\n\n-- Running an example\nrunConsumerExample
  :: IO ()\nrunConsumerExample = do\n    res <- runConsumer consumerProps consumerSub
  processMessages\n    print res\n\n-------------------------------------------------------------------\nprocessMessages
  :: KafkaConsumer -> IO (Either KafkaError ())\nprocessMessages kafka = do\n    mapM_
  (\\_ -> do\n                   msg1 <- pollMessage kafka (Timeout 1000)\n                   putStrLn
  $ \"Message: \" <> show msg1\n                   err <- commitAllOffsets kafka OffsetCommit\n
  \                  putStrLn $ \"Offsets: \" <> maybe \"Committed.\" show err\n          )
  [0 .. 10]\n    return $ Right ()\n```\n\n# Producer\n`kafka-client` producer supports
  sending messages to multiple topics.\nTarget topic name is a part of each message
  that is to be sent by `produceMessage`.\n\nA working producer example can be found
  here: [ProducerExample.hs](example/ProducerExample.hs)\n\n### Example\n\n```Haskell\nimport
  Control.Monad (forM_)\nimport Kafka\nimport Kafka.Producer\n\n-- Global producer
  properties\nproducerProps :: ProducerProperties\nproducerProps = brokersList [BrokerAddress
  \"localhost:9092\"]\n             <> logLevel KafkaLogDebug\n\n-- Topic to send
  messages to\ntargetTopic :: TopicName\ntargetTopic = TopicName \"kafka-client-example-topic\"\n\n--
  Run an example\nrunProducerExample :: IO ()\nrunProducerExample = do\n    res <-
  runProducer producerProps sendMessages\n    print res\n\nsendMessages :: KafkaProducer
  -> IO (Either KafkaError ())\nsendMessages prod = do\n  err1 <- produceMessage prod
  (mkMessage Nothing (Just \"test from producer\") )\n  forM_ err1 print\n\n  err2
  <- produceMessage prod (mkMessage (Just \"key\") (Just \"test from producer (with
  key)\"))\n  forM_ err2 print\n\n  return $ Right ()\n\nmkMessage :: Maybe ByteString
  -> Maybe ByteString -> ProducerRecord\nmkMessage k v = ProducerRecord\n                  {
  prTopic = targetTopic\n                  , prPartition = UnassignedPartition\n                  ,
  prKey = k\n                  , prValue = v\n                  }\n```\n\n# Installation\n\n##
  Installing librdkafka\n\nAlthough `librdkafka` is available on many platforms, most
  of\nthe distribution packages are too old to support `kafka-client`.\nAs such, we
  suggest you install from the source:\n\n    git clone https://github.com/edenhill/librdkafka\n
  \   cd librdkafka\n    ./configure\n    make && make install\n\nSometimes it is
  helpful to specify openssl includes explicitly:\n\n    LDFLAGS=-L/usr/local/opt/openssl/lib
  CPPFLAGS=-I/usr/local/opt/openssl/include ./configure\n\n## Installing Kafka\n\nThe
  full Kafka guide is at http://kafka.apache.org/documentation.html#quickstart\n\nAlternatively
  `docker-compose` can be used to run Kafka locally inside a Docker container.\nTo
  run Kafka inside Docker:\n\n```\n$ docker-compose up\n```\n"
license-name: MIT
