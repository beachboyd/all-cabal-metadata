homepage: http://github.com/composewell/concurrency-benchmarks
changelog-type: markdown
hash: d55ad7c2c6f365c6d5f830dd015b18cbeb9284a0464bf4f4f69d5c262c32adfe
test-bench-deps:
  base: ==4.*
  async: ! '>=2.1.1 && <2.3'
  gauge: ! '>=0.2.1 && <0.3'
  mtl: ! '>=2 && <2.3'
  transformers: ! '>=0.4 && <0.6'
  random: ! '>=1.0 && <2'
  deepseq: ! '>=1.4.0 && <1.5'
  streamly: ! '>=0.4.0 && <0.6'
maintainer: Harendra Kumar
synopsis: Benchmarks to compare concurrency APIs
changelog: ! '## 0.1.1


  * Update version bounds


  ## 0.1.0


  * Initial release

'
basic-deps:
  Chart: ! '>=1.6 && <2'
  bytestring: ! '>=0.9 && <0.11'
  Chart-diagrams: ! '>=1.6 && <2'
  split: ! '>=0.2 && <0.3'
  base: ==4.*
  text: ! '>=1.1.1 && <1.3'
  bench-graph: ! '>=0.1 && <0.2'
  csv: ! '>=0.1 && <0.2'
  typed-process: ! '>=0.1.0.0 && <0.3'
  getopt-generics: ! '>=0.11 && <0.14'
  transformers: ! '>=0.4 && <0.6'
  directory: ! '>=1.2 && <1.4'
all-versions:
- '0.1.0'
- '0.1.1'
author: Harendra Kumar
latest: '0.1.1'
description-type: markdown
description: ! "# concurrency-benchmarks\n\n[![Hackage](https://img.shields.io/hackage/v/concurrency-benchmarks.svg?style=flat)](https://hackage.haskell.org/package/concurrency-benchmarks)\n[![Build
  Status](https://travis-ci.org/composewell/concurrency-benchmarks.svg?branch=master)](https://travis-ci.org/composewell/concurrency-benchmarks)\n[![Windows
  Build status](https://ci.appveyor.com/api/projects/status/wqban615v9f21xqi?svg=true)](https://ci.appveyor.com/project/harendra-kumar/concurrency-benchmarks)\n\nBenchmarks
  to compare the pure concurrency overhead of various flavors of\nconcurrent [streamly](https://github.com/composewell/streamly)
  streams and the\n[async](https://hackage.haskell.org/package/async) package.\n\nRun
  the `run.sh` script to run the benchmarks and create the charts. You can\nuse `cabal
  new-bench` or `stack bench` to run the benchmarks. To generate\ncharts, run the
  benchmarks with `--csv-raw=results.csv` option and then run\n`makecharts results.csv`.
  Charts are generated in the `charts` directory.\n\n## Methodology\n\nA total of
  10,000 tasks are run for each concurrency mechanism being compared.\nTwo independent
  experiments are performed:\n\n1. In the first experiment, each task is just a noop
  i.e. it takes almost 0 time\n   to execute.\n2. In the second experiment, each task
  introduces a 5 second delay\n\nThe first case shows streamly's smart scheduling
  to automatically run the tasks\nin less number of threads than the actual number
  of tasks.  When the tasks do\nnot block and have a very low latency, streamly may
  run multiple tasks per\nthread.  Therefore streamly is much faster on this benchmark.\n\nIn
  the second case a 5 second delay is introduced to make sure that streamly\nuses
  one thread per task which is similar to what `async` does and therefore a\nfair
  comparison.  For the `async` package, `mapConcurrently` is used which can\nbe compared
  with streamly's `ahead` style stream.\n\nFor streamly this is the code that is benchmarked,
  by default streamly has a\nlimit on the buffer size and the number of threads, we
  set those limits to `-1`\nwhich means there is no limit:\n\n```haskell\n    let
  work = (\\i -> threadDelay 5000000 >> return i)\n    in runStream\n        $ aheadly\n
  \       $ maxBuffer (-1)\n        $ maxThreads (-1)\n        $ S.fromFoldableM $
  map work [1..10000]\n```\n\nFor `async` this is the code that is benchmarked:\n\n```haskell\n
  \   let work = (\\i -> threadDelay 5000000 >> return i)\n    mapConcurrently work
  [1..10000]\n```\n\n## Results\n\nThese charts compare\n[streamly-0.5.1](https://hackage.haskell.org/package/streamly)
  and\n`async-2.2.1` on a MacBook Pro with a 2.2 GHz Intel Core i7 processor.\n\nWhen
  compiling, `-threaded -with-rtsopts \"-N\"` GHC options were used to enable\nthe
  use of multiple processor cores in parallel.\n\nFor streamly, results for both `async`
  and `ahead` style streams are shown.\n\n### Zero delay case\n\n#### Peak Memory
  Consumed\n\n<img src=\"https://github.com/composewell/concurrency-benchmarks/blob/master/charts/10,000tasks,0secdelay-maxrss.svg\"
  alt=\"Comparison of maxrss\" width=\"640\"/>\n\n#### Time Taken\n\n<img src=\"https://github.com/composewell/concurrency-benchmarks/blob/master/charts/10,000tasks,0secdelay-time.svg\"
  alt=\"Comparison of time\" width=\"640\"/>\n\n### 5 second delay case\n\n#### Peak
  Memory Consumed\n\n<img src=\"https://github.com/composewell/concurrency-benchmarks/blob/master/charts/10,000tasks,5secdelay-maxrss.svg\"
  alt=\"Comparison of maxrss\" width=\"640\"/>\n\n#### Time Taken\n\nNote, this time
  shows the overhead only and not the full time taken by the\nbenchmark. For example
  the actual time taken by the `async` benchmark is\n`5.135` seconds, but since 5
  second in this is the delay introduced by each\nparallel task, we compute the overhead
  of concurrency by deducting the 5\nseconds from the actual time taken, so the overhead
  is `135 ms` in case of\n`async`.\n\n<img src=\"https://github.com/composewell/concurrency-benchmarks/blob/master/charts/10,000tasks,5secdelay-time.svg\"
  alt=\"Comparison of time\" width=\"640\"/>\n\n## Feedback\n\nFeedback is welcome.
  Please raise an issue, send a PR or send an email to the\nauthor.\n"
license-name: MIT
