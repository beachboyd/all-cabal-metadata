homepage: https://github.com/ezyang/compact
changelog-type: markdown
hash: a74976cfdb16a76ca006b58f2a952d604e3244b404e0458a1ec1c255d7d7c8eb
test-bench-deps:
  compact: -any
  base: -any
  directory: -any
maintainer: ezyang@mit.edu, ben@smart-cactus.org
synopsis: Non-GC'd, contiguous storage for immutable data structures
changelog: ! '# Revision history for compact


  ## 0.1.0.0  -- 2017-02-27


  * First version.

'
basic-deps:
  bytestring: ! '>=0.10 && <0.11'
  base: ! '>=4.10 && <4.13'
  ghc-compact: -any
  binary: ! '>=0.8.4.1 && <0.9'
all-versions:
- '0.1.0.0'
- '0.1.0.1'
author: Edward Z. Yang, Ben Gamari
latest: '0.1.0.1'
description-type: markdown
description: ! "# compact\n\n[![Hackage version](https://img.shields.io/hackage/v/compact.svg?label=Hackage)](https://hackage.haskell.org/package/compact)\n\n*Non-GC'd,
  contiguous storage for immutable data structures.*\n\nThis package provides user-facing
  APIs for working with \"compact regions\", which\nhold a fully evaluated Haskell
  object graph.  These regions maintain the\ninvariant that no pointers live inside
  the struct that point outside it, which\nensures efficient garbage collection without
  ever reading the structure contents\n(effectively, it works as a manually managed
  \"oldest generation\" which is never\nfreed until the whole is released).\n\nWhen
  would you want to use a compact region? The simplest use case is this: you\nhave
  some extremely large, long-lived, pointer data structure which GHC has\nuselessly
  been tracing when you have a major collection. If you place this\nstructure in a
  compact region, after the initial cost of copying the data into\nthe region, you
  should see a speedup in your major GC runs.\n\nThis package is currently highly
  experimental, but we hope it may be useful to\nsome people.  It is GHC 8.2 only.
  \ The bare-bones library that ships with GHC is\nghc-compact.\n\n## Quick start\n\n*
  Import `Data.Compact`\n\n* Put some data in a compact region with `compact :: a
  -> IO (Compact a)`,\n  e.g., `cr <- compact someBigDataStructure`, fully evaluating
  it in\n  the process.\n\n* Use `getCompact :: Compact a -> a` to get a pointer inside
  the region,\n  e.g., `operateOnDataStructure (getCompact cr)`.  The data pointed
  to\n  by these pointers will not participate in GC.\n\n* Import `Data.Compact.Serialize`
  to write and read compact regions from files.\n\n## Tutorial\n\n**Garbage collection
  savings.** It's a little difficult to construct a\ncompelling, small example showing
  the benefit, but here is a very simple case\nfrom the `nofib` test suite, the `spellcheck`
  program.  `spellcheck` is a very\nsimple program which reads a dictionary into a
  set, and then tests an input\nword-by-word to see if it is in the set or not (yes,
  it is a *very* simple\nspell checker):\n\n```\nimport System.Environment (getArgs)\nimport
  qualified Data.Set as Set\nimport System.IO\n\nmain = do\n  [file1,file2] <- getArgs\n
  \ dict <- readFileLatin1 file1\n  input <- readFileLatin1 file2\n  let set = Set.fromList
  (words dict)\n  let tocheck = words input\n  print (filter (`Set.notMember` set)
  tocheck)\n\nreadFileLatin1 f = do\n  h <- openFile f ReadMode\n  hSetEncoding h
  latin1\n  hGetContents h\n```\n\nConverting this program to use a compact region
  on the dictionary is very\nsimple: add `import Data.Compact`, and convert `let set
  = Set.fromList (words\ndict)` to read `set <- fmap getCompact (compact (Set.fromList
  (words dict)))`:\n\n```\nimport System.Environment (getArgs)\nimport qualified Data.Set
  as Set\nimport System.IO\nimport Data.Compact -- **\n\nmain = do\n  [file1,file2]
  <- getArgs\n  dict <- readFileLatin1 file1\n  input <- readFileLatin1 file2\n  set
  <- fmap getCompact (compact (Set.fromList (words dict))) -- ***\n  let tocheck =
  words input\n  print (filter (`Set.notMember` set) tocheck)\n\nreadFileLatin1 f
  = do\n  h <- openFile f ReadMode\n  hSetEncoding h latin1\n  hGetContents h\n```\n\nBreaking
  down the new line: `compact` takes an argument `a` which must be pure\nand immutable
  and then copies it into a compact region. This function returns a\n`Compact a` pointer,
  which is simultaneously a handle to the compact region as\nwell as the data you
  copied into it.  You get back the actual `a` data that\nlives in the region using
  `getCompact`.\n\nUsing the sample `nofib` input\n([words](https://github.com/ghc/nofib/blob/master/gc/spellcheck/words)
  and\n[input](https://github.com/ghc/nofib/blob/master/gc/spellcheck/input>)), we
  can take\na look at our GC stats before and after the change.  To make the effect
  more\npronounced, I've reduced the allocation area size to 256K, so that we do more\nmajor
  collections.  Here are the stats with the original:\n\n```\n   1,606,462,200 bytes
  allocated in the heap\n     727,499,032 bytes copied during GC\n      24,050,160
  bytes maximum residency (21 sample(s))\n         107,144 bytes maximum slop\n              71
  MB total memory in use (0 MB lost due to fragmentation)\n\n                                     Tot
  time (elapsed)  Avg pause  Max pause\n  Gen  0      6119 colls,     0 par    0.743s
  \  0.754s     0.0001s    0.0023s\n  Gen  1        21 colls,     0 par    0.608s
  \  0.611s     0.0291s    0.0582s\n\n  INIT    time    0.000s  (  0.000s elapsed)\n
  \ MUT     time    2.012s  (  2.024s elapsed)\n  GC      time    1.350s  (  1.365s
  elapsed)\n  EXIT    time    0.000s  (  0.000s elapsed)\n  Total   time    3.363s
  \ (  3.389s elapsed)\n\n  %GC     time      40.2%  (40.3% elapsed)\n\n  Alloc rate
  \   798,416,807 bytes per MUT second\n\n  Productivity  59.8% of total user, 59.7%
  of total elapsed\n```\n\nHere are the stats with compact regions:\n\n```\n   1,630,448,408
  bytes allocated in the heap\n     488,392,976 bytes copied during GC\n      24,104,152
  bytes maximum residency (21 sample(s))\n          76,144 bytes maximum slop\n              55
  MB total memory in use (0 MB lost due to fragmentation)\n\n                                     Tot
  time (elapsed)  Avg pause  Max pause\n  Gen  0      6119 colls,     0 par    0.755s
  \  0.770s     0.0001s    0.0017s\n  Gen  1        21 colls,     0 par    0.147s
  \  0.147s     0.0070s    0.0462s\n\n  INIT    time    0.000s  (  0.000s elapsed)\n
  \ MUT     time    1.999s  (  2.054s elapsed)\n  GC      time    0.902s  (  0.918s
  elapsed)\n  EXIT    time    0.000s  (  0.000s elapsed)\n  Total   time    2.901s
  \ (  2.972s elapsed)\n\n  %GC     time      31.1%  (30.9% elapsed)\n\n  Alloc rate
  \   815,689,434 bytes per MUT second\n\n  Productivity  68.9% of total user, 69.1%
  of total elapsed\n```\n\nYou can see that while the version of the program with
  compact regions allocates\nslightly more (since it performs a copy on the set),
  it copies nearly half as\nmuch data during GC, reducing the time spent in major
  GCs by a factor of three.\nOn this particular example, you don't actually save that
  much time overall\n(since the bulk of execution is spent in the mutator)--a reminder
  that one\nshould always measure before one optimizes.\n\n**Serializing to disk.**\nYou
  can take the data in a compact region and save it to disk, so that you can\nload
  it up at a later point in time.  This functionality is provided by\n`Data.Compact.Serialized`:
  `writeCompact` and `unsafeReadCompact` let you\nwrite a compact to a file, and read
  it back again:\n\n```\n{-# LANGUAGE TypeApplications #-}\nimport Data.Compact\nimport
  Data.Compact.Serialize\nmain = do\n    orig_c <- compact (\"I want to serialize
  this\", True)\n    writeCompact @(String, Bool) \"somefile\" orig_c\n    res <-
  unsafeReadCompact @(String, Bool) \"somefile\"\n    case res of\n        Left err
  -> fail err\n        Right c -> print (getCompact c)\n```\n\nCompact regions written
  to handles this way are subject to some\nrestrictions:\n\n* Our binary representation
  contains direct pointers to the info\n  tables of objects in the region.  This means
  that the info tables\n  of the receiving process must be laid out in exactly the
  same\n  way as from the original process; in practice, this means using\n  static
  linking, using the exact same binary and turning off ASLR.  This\n  API does NOT
  do any safety checking and will probably segfault if you\n  get it wrong.  DO NOT
  run `unsafeReadCompact` on untrusted input.\n\n* You must read out the value at
  the correct type.  We will\n  check this for you and raise an error if the types
  do not match.\n  To tell `unsafeReadCompact` what type it should read out with,\n
  \ the `TypeApplications` extension may come in handy (this extension\n  is guaranteed
  to be available, since compact only supports GHC 8.2\n  or later!)\n"
license-name: BSD3
