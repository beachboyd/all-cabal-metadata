homepage: ''
changelog-type: markdown
hash: 1a119a0ca4ee201a61b65d57da608dc092d4138998ac0abfce4ea9110861feb7
test-bench-deps:
  htoml: -any
  base: -any
  unordered-containers: -any
  hspec: -any
  text: -any
  criterion: -any
  Frames: -any
  HUnit: -any
  vinyl: -any
  lens: -any
  pipes: ! '>=4.1.5 && <4.4'
  foldl: ! '>=1.3 && <1.5'
  attoparsec: -any
  regex-applicative: -any
  transformers: -any
  temporary: -any
  pretty: -any
  template-haskell: -any
  directory: -any
maintainer: acowley@gmail.com
synopsis: Data frames For working with tabular data files
changelog: ! '# 0.6.0

  Support external CSV tokenizers


  Internal functionality is now defined more cleanly atop a stream of rows already
  broken into columns (rather than a stream of rows that we quietly break into columns
  ourself). This permits the use of external parsers such as provided by the new [Frames-dsv](https://hackage.haskell.org/package/Frames-dsv)
  package that supplies a CSV parser built atop `hw-dsv`.


  The built-in CSV parser remains for ease of installation.


  # 0.5.1

  GHC 8.6 compatibility


  # 0.5.0


  - Renamed the `rgetf` and `rputf` exported by the `Frames` module to `rgetField`
  and `rputField`. This avoids clashing with the same names exported by `vinyl` and
  further advances the process of eliminating the old `Frames` `Col` type in favor
  of `vinyl`''s `ElField`.


  - Add a `ShowCSV` class rather than leaning on overburdened `Show` instances.


  - Add support for categorical column types: values of these types are one of a small
  number of textual values. Because they can only take on a small number of different
  text values, we can compactly represent values of these types as standard Haskell
  sum types.


  # 0.4.0


  - Added table joins in `Data.Vinyl.Joins` (Chris Hammill)


  - Changed types of `mapMethod` and `mapMethodV`


  These now rely on explicit `TypeApplications` rather than `Proxy` values.


  # 0.3.0


  - Pervasive use of `pipes` for CSV data loading


  This provides better exception handling (file handles should be closed more reliably),
  and offers an interface point for customized handling of input texts. An example
  of this latter point is working with particular file encodings.


  A breaking change is that operations that previously returned `IO` values now return
  `MonadSafe` constrained values.


  - Adaptation of `Data.Vinyl.Curry.runcurry` to the Frames `Record` type

  This simply strips the column name information from a row before applying the function
  from `vinyl`.


  # 0.2.1


  - Refactored to use the `CoRec` type provided by `vinyl` >= 0.6.0


  - Fixed bug in typing mostly-numeric columns

  Such columns must be represented as `Text`. Previously, we strove a bit too hard
  to avoid falling back to `Text` resulting in dropping rows containing non-numeric
  values for columns we crammed into a numeric type.


  - Minor optimization of CSV parsing

  In particular, dealing with RFC4180 style quoting


  - GHC-8.2.1 compatibility


  # 0.1.10


  - Added CSV output functions: `produceCSV` and `writeCSV`

  - Added an Eq instance for the `Frame` type



  # 0.1.9


  Fixed column type inference bug that led the inferencer to prefer `Bool` too strongly.


  This was fallout from typing columns whose values are all 0 or 1 as `Bool`.


  # 0.1.6


  Re-export `Frames.CSV.declareColumn` from `Frames`. This makes it much

  easier to manually define column types.


  # 0.1.4


  Use `microlens` instead of `lens-family-core` for demos.


  # 0.1.3


  GHC-8.0.1 compatibility


  # 0.1.2.1


  Improved documentation based on suggestions by Alexander Kjeldaas


  # 0.1.2


  Fixed bug in `Monoid` instance of `Frame` (@dalejordan)


  # 0.1.1.0


  Added `frameConsA`, `frameSnoc`, and `RecordColumns` to help with

  changing row types.


  # 0.1.0.0


  Initial version pushed to hackage.

'
basic-deps:
  bytestring: -any
  base: ! '>=4.8 && <4.13'
  pipes-bytestring: ! '>=2.1.6 && <2.2'
  pipes-group: ! '>=1.0.8 && <1.1'
  text: ! '>=1.1.1.0'
  containers: -any
  vinyl: ! '>=0.10.0 && <0.11'
  pipes-parse: ! '>=3.0 && <3.1'
  pipes: ! '>=4.1 && <5'
  ghc-prim: ! '>=0.3 && <0.6'
  contravariant: -any
  hashable: -any
  readable: ! '>=0.3.1'
  transformers: -any
  deepseq: ! '>=1.4'
  vector-th-unbox: ! '>=0.2.1.6'
  pipes-safe: ! '>=2.2.6 && <2.4'
  template-haskell: -any
  discrimination: -any
  primitive: ! '>=0.6 && <0.7'
  vector: -any
all-versions:
- '0.1.0.0'
- '0.1.1.0'
- '0.1.1.1'
- '0.1.2'
- '0.1.2.1'
- '0.1.3'
- '0.1.4'
- '0.1.6'
- '0.1.8'
- '0.1.9'
- '0.2.0'
- '0.2.1'
- '0.2.1.1'
- '0.3.0'
- '0.3.0.1'
- '0.3.0.2'
- '0.4.0'
- '0.5.0'
- '0.5.1'
- '0.6.0'
author: Anthony Cowley
latest: '0.6.0'
description-type: markdown
description: ! "# Frames\n\n\n## Data Frames for Haskell\n\nUser-friendly, type safe,
  runtime efficient tooling for working with tabular data deserialized from comma-separated
  values (CSV) files. The type of each row of data is inferred from data, which can
  then be streamed from disk, or worked with in memory.\n\nWe provide streaming and
  in-memory interfaces for efficiently working with datasets that can be safely indexed
  by column names found in the data files themselves. This type safety of column access
  and manipulation is checked at compile time.\n\n\n## Use Cases\n\nFor a running
  example, we will use variations of the [prestige.csv](http://vincentarelbundock.github.io/Rdatasets/datasets.html)
  data set. Each row includes 7 columns, but we just want to compute the average ratio
  of `income` to `prestige`.\n\n\n### Clean Data\n\nIf you have a CSV data where the
  values of each column may be classified by a single type, and ideally you have a
  header row giving each column a name, you may simply want to avoid writing out the
  Haskell type corresponding to each row. `Frames` provides `TemplateHaskell` machinery
  to infer a Haskell type for each row of your data set, thus preventing the situation
  where your code quietly diverges from your data.\n\nWe generate a collection of
  definitions generated by inspecting the data file at compile time (using `tableTypes`),
  then, at runtime, load that data into column-oriented storage in memory (an **in-core**
  array of structures (AoS)). We're going to compute the average ratio of two columns,
  so we'll use the `foldl` library. Our fold will project the columns we want, and
  apply a function that divides one by the other after appropriate numeric type conversions.
  Here is the entirety of that [program](https://github.com/acowley/Frames/tree/master/test/UncurryFold.hs).\n\n```haskell\n{-#
  LANGUAGE DataKinds, FlexibleContexts, QuasiQuotes, TemplateHaskell #-}\nmodule UncurryFold
  where\nimport qualified Control.Foldl as L\nimport Data.Vinyl (rcast)\nimport Data.Vinyl.Curry
  (runcurryX)\nimport Frames\n\n-- Data set from http://vincentarelbundock.github.io/Rdatasets/datasets.html\ntableTypes
  \"Row\" \"test/data/prestige.csv\"\n\nloadRows :: IO (Frame Row)\nloadRows = inCoreAoS
  (readTable \"test/data/prestige.csv\")\n\n-- | Compute the ratio of income to prestige
  for a record containing\n-- only those fields.\nratio :: Record '[Income, Prestige]
  -> Double\nratio = runcurryX (\\i p -> fromIntegral i / p)\n\naverageRatio :: IO
  Double\naverageRatio = L.fold (L.premap (ratio . rcast) avg) <$> loadRows\n  where
  avg = (/) <$> L.sum <*> L.genericLength\n```\n\n\n### Missing Header Row\n\nNow
  consider a case where our data file lacks a header row (I deleted the first row
  from \\`prestige.csv\\`). We will provide our own name for the generated row type,
  our own column names, and, for the sake of demonstration, we will also specify a
  prefix to be added to every column-based identifier (particularly useful if the
  column names **do** come from a header row, and you want to work with multiple CSV
  files some of whose column names coincide). We customize behavior by updating whichever
  fields of the record produced by `rowGen` we care to change, passing the result
  to `tableTypes'`. [Link to code.](https://github.com/acowley/Frames/tree/master/test/UncurryFoldNoHeader.hs)\n\n```haskell\n{-#
  LANGUAGE DataKinds, FlexibleContexts, QuasiQuotes, TemplateHaskell #-}\nmodule UncurryFoldNoHeader
  where\nimport qualified Control.Foldl as L\nimport Data.Vinyl (rcast)\nimport Data.Vinyl.Curry
  (runcurryX)\nimport Frames\nimport Frames.TH (rowGen, RowGen(..))\n\n-- Data set
  from http://vincentarelbundock.github.io/Rdatasets/datasets.html\ntableTypes' (rowGen
  \"test/data/prestigeNoHeader.csv\")\n            { rowTypeName = \"NoH\"\n            ,
  columnNames = [ \"Job\", \"Schooling\", \"Money\", \"Females\"\n                            ,
  \"Respect\", \"Census\", \"Category\" ]\n            , tablePrefix = \"NoHead\"}\n\nloadRows
  :: IO (Frame NoH)\nloadRows = inCoreAoS (readTableOpt noHParser \"test/data/prestigeNoHeader.csv\")\n\n--
  | Compute the ratio of money to respect for a record containing\n-- only those fields.\nratio
  :: Record '[NoHeadMoney, NoHeadRespect] -> Double\nratio = runcurryX (\\m r -> fromIntegral
  m / r)\n\naverageRatio :: IO Double\naverageRatio = L.fold (L.premap (ratio . rcast)
  avg) <$> loadRows\n  where avg = (/) <$> L.sum <*> L.genericLength\n```\n\n\n###
  Missing Data\n\nSometimes not every row has a value for every column. I went ahead
  and blanked the `prestige` column of every row whose `type` column was `NA` in `prestige.csv`.
  For example, the first such row now reads,\n\n    \"athletes\",11.44,8206,8.13,,3373,NA\n\nWe
  can no longer parse a `Double` for that row, so we will work with row types parameterized
  by a `Maybe` type constructor. We are substantially filtering our data, so we will
  perform this operation in a streaming fashion without ever loading the entire table
  into memory. Our process will be to check if the `prestige` column was parsed, only
  keeping those rows for which it was not, then project the `income` column from those
  rows, and finally throw away `Nothing` elements. [Link to code](https://github.com/acowley/Frames/tree/master/test/UncurryFoldPartialData.hs).\n\n```haskell\n{-#
  LANGUAGE DataKinds, FlexibleContexts, QuasiQuotes, TemplateHaskell, TypeApplications,
  TypeOperators #-}\nmodule UncurryFoldPartialData where\nimport qualified Control.Foldl
  as L\nimport Data.Maybe (isNothing)\nimport Data.Vinyl.XRec (toHKD)\nimport Frames\nimport
  Pipes (Producer, (>->))\nimport qualified Pipes.Prelude as P\n\n-- Data set from
  http://vincentarelbundock.github.io/Rdatasets/datasets.html\n-- The prestige column
  has been left blank for rows whose \"type\" is\n-- listed as \"NA\".\ntableTypes
  \"Row\" \"test/data/prestigePartial.csv\"\n\n-- | A pipes 'Producer' of our 'Row'
  type with a column functor of\n-- 'Maybe'. That is, each element of each row may
  have failed to parse\n-- from the CSV file.\nmaybeRows :: MonadSafe m => Producer
  (Rec (Maybe :. ElField) (RecordColumns Row)) m ()\nmaybeRows = readTableMaybe \"test/data/prestigePartial.csv\"\n\n--
  | Return the number of rows with unknown prestige, and the average\n-- income of
  those rows.\nincomeOfUnknownPrestige :: IO (Int, Double)\nincomeOfUnknownPrestige
  =\n  runSafeEffect . L.purely P.fold avg $\n    maybeRows >-> P.filter prestigeUnknown
  >-> P.map getIncome >-> P.concat\n  where avg = (\\s l -> (l, s / fromIntegral l))
  <$> L.sum <*> L.length\n        getIncome = fmap fromIntegral . toHKD . rget @Income\n
  \       prestigeUnknown :: Rec (Maybe :. ElField) (RecordColumns Row) -> Bool\n
  \       prestigeUnknown = isNothing . toHKD . rget @Prestige\n```\n\n\n## Tutorial\n\nFor
  comparison to working with data frames in other languages, see the [tutorial](http://acowley.github.io/Frames/).\n\n\n##
  Demos\n\nThere are various [demos](https://github.com/acowley/Frames/tree/master/demo)
  in the repository. Be sure to run the `getdata` build target to download the data
  files used by the demos! You can also download the data files manually and put them
  in a `data` directory in the directory from which you will be running the executables.\n\n\n##
  Benchmarks\n\nThe [benchmark](https://github.com/acowley/Frames/tree/master/benchmarks/InsuranceBench.hs)
  shows several ways of dealing with data when you want to perform multiple traversals.\n\nAnother
  [demo](https://github.com/acowley/Frames/tree/master/benchmarks/BenchDemo.hs) shows
  how to fuse multiple passes into one so that the full data set is never resident
  in memory. A [Pandas version](https://github.com/acowley/Frames/tree/master/benchmarks/panda.py)
  of a similar program is also provided for comparison.\n\nThis is a trivial program,
  but shows that performance is comparable to Pandas, and the memory savings of a
  compiled program are substantial.\n\n![img](https://pbs.twimg.com/media/B71az_CCUAAgscq.png)\n"
license-name: BSD3
