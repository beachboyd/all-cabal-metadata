homepage: https://github.com/Gabriel439/bench
changelog-type: ''
hash: 5a04ec59eddaa47b83927fe009fd28480c3f31ff9a4b7dd4e7d37fe38e4f5385
test-bench-deps: {}
maintainer: Gabriel439@gmail.com
synopsis: Command-line benchmark tool
changelog: ''
basic-deps:
  base: ! '>=4.5 && <5'
  text: <1.3
  criterion: ! '>=1.4 && <1.6'
  process: ! '>=1.3 && <1.7'
  turtle: ! '>=1.2.5 && <1.6'
  silently: ! '>=1.1.1 && <1.3'
  optparse-applicative: ! '>=0.14.0.0 && <0.15'
all-versions:
- '1.0.1'
- '1.0.2'
- '1.0.3'
- '1.0.4'
- '1.0.5'
- '1.0.6'
- '1.0.7'
- '1.0.8'
- '1.0.9'
- '1.0.10'
- '1.0.11'
author: Gabriel Gonzalez
latest: '1.0.11'
description-type: markdown
description: ! "# Bench v1.0.11\n\nThis project provides the `bench` command-line
  tool, which is a more powerful\nalternative to the `time` command.  Use `bench`
  to benchmark a command using\nHaskell's `criterion` library.\n\nKey features:\n\n*
  Repeated runs\n* Detailed statistical output\n* Gorgeous HTML output (via the `--output`
  flag)\n  ([Example](http://www.serpentine.com/criterion/fibber.html))\n* Also supports
  CSV or templated output\n\n## Quick Start\n\nYou can install `bench` on macOS via
  [Homebrew](http://braumeister.org/formula/bench):\n\n```bash\n$ brew install bench\n```\n\n...
  or you can install `bench` using Haskell's `stack` tool.  To do that, first\ndownload
  the [Haskell toolchain](https://www.haskell.org/downloads#minimal),\nwhich provides
  the `stack` tool, then run:\n\n```bash\n$ stack setup\n$ stack install bench\n```\n\n`stack
  install` will install `bench` to `~/.local/bin` or something similar.\nMake sure
  that the installation directory is on your executable search path\nbefore running
  `bench`.  `stack` will remind you to do this if you forget.\n\nAnother alternative
  is to use [Nix package manager](https://nixos.org/nix/). After its installation
  just execute:\n\n```$ nix-env -i bench```\n\nOnce you've installed `bench` (either
  by download or installation via `stack` or Nix),\nyou can begin benchmarking programs:\n\n```bash\n$
  bench 'sleep 1'  # Don't forget to quote the command line\nbenchmarking sleep 1\ntime
  \                1.003 s    (1.002 s .. 1.003 s)\n                     1.000 R²
  \  (1.000 R² .. 1.000 R²)\nmean                 1.003 s    (1.003 s .. 1.003 s)\nstd
  dev              92.92 μs   (0.0 s .. 101.8 μs)\nvariance introduced by outliers:
  19% (moderately inflated)\n\n$ bench true\nbenchmarking true\ntime                 410.3
  μs   (382.3 μs .. 443.3 μs)\n                     0.974 R²   (0.961 R² .. 0.987
  R²)\nmean                 420.7 μs   (406.8 μs .. 435.7 μs)\nstd dev              47.69
  μs   (40.09 μs .. 57.91 μs)\nvariance introduced by outliers: 81% (severely inflated)\n```\n\nAll
  output from the command being benchmarked is discarded.\n\nMultiple commands are
  also supported:\n\n```bash\n$ bench id ls \"sleep 0.1\"\nbenchmarking bench/id\ntime
  \                4.798 ms   (4.764 ms .. 4.833 ms)\n                     0.999 R²
  \  (0.998 R² .. 1.000 R²)\nmean                 4.909 ms   (4.879 ms .. 4.953 ms)\nstd
  dev              104.6 μs   (78.91 μs .. 135.7 μs)\n\nbenchmarking bench/ls\ntime
  \                2.941 ms   (2.889 ms .. 3.006 ms)\n                     0.996 R²
  \  (0.992 R² .. 0.998 R²)\nmean                 3.051 ms   (3.015 ms .. 3.094 ms)\nstd
  dev              129.7 μs   (104.3 μs .. 178.3 μs)\nvariance introduced by outliers:
  25% (moderately inflated)\n\nbenchmarking bench/sleep 0.1\ntime                 109.9
  ms   (108.5 ms .. 111.0 ms)\n                     1.000 R²   (1.000 R² .. 1.000
  R²)\nmean                 109.2 ms   (108.5 ms .. 109.7 ms)\nstd dev              903.0
  μs   (676.4 μs .. 1.212 ms)\n```\n\nYou can also output an HTML file graphing the
  distribution of\ntimings by using the `--output` flag:\n\n```bash\n$ bench 'ls /usr/bin
  | wc -l' --output example.html\nbenchmarking ls /usr/bin | wc -l\ntime                 6.716
  ms   (6.645 ms .. 6.807 ms)\n                     0.999 R²   (0.999 R² .. 0.999
  R²)\nmean                 7.005 ms   (6.897 ms .. 7.251 ms)\nstd dev              462.0
  μs   (199.3 μs .. 809.2 μs)\nvariance introduced by outliers: 37% (moderately inflated)\n```\n\n...
  and if you open that page in your browser you will\nget something that looks like
  this:\n\n![](http://i.imgur.com/2MCKBc2.png)\n\n## Usage\n\n```\n$ bench --help\nCommand-line
  tool to benchmark other programs\n\nUsage: bench COMMAND ([-I|--ci CI] [-G|--no-gc]
  [-L|--time-limit SECS]\n             [--resamples COUNT] [--regress RESP:PRED..]
  [--raw FILE]\n             [-o|--output FILE] [--csv FILE] [--junit FILE]\n             [-v|--verbosity
  LEVEL] [-t|--template FILE] [-m|--match MATCH]\n             [NAME...] | [-n|--iters
  ITERS] [-m|--match MATCH] [NAME...] |\n             [-l|--list] | [--version])\n\nAvailable
  options:\n  -h,--help                Show this help text\n  COMMAND                  The
  command line to benchmark\n  -I,--ci CI               Confidence interval\n  -G,--no-gc
  \              Do not collect garbage between iterations\n  -L,--time-limit SECS
  \    Time limit to run a benchmark\n  --resamples COUNT        Number of bootstrap
  resamples to perform\n  --regress RESP:PRED..    Regressions to perform\n  --raw
  FILE               File to write raw data to\n  -o,--output FILE         File to
  write report to\n  --csv FILE               File to write CSV summary to\n  --junit
  FILE             File to write JUnit summary to\n  -v,--verbosity LEVEL     Verbosity
  level\n  -t,--template FILE       Template to use for report\n  -m,--match MATCH
  \        How to match benchmark names (\"prefix\" or \"glob\")\n  -n,--iters ITERS
  \        Run benchmarks, don't analyse\n  -m,--match MATCH         How to match
  benchmark names (\"prefix\" or \"glob\")\n  -l,--list                List benchmarks\n
  \ --version                Show version info\n```\n\n## Development Status\n\n[![Build
  Status](https://travis-ci.org/Gabriel439/bench.png)](https://travis-ci.org/Gabriel439/bench)\n\nThis
  is a pretty simple utility which just wraps `criterion` in a command-line\ntool,
  so I don't expect this project to change much.  However, only time will\ntell.\n\n##
  License (BSD 3-clause)\n\nCopyright Gabriel Gonzalez (c) 2016\n\nAll rights reserved.\n\nRedistribution
  and use in source and binary forms, with or without\nmodification, are permitted
  provided that the following conditions are met:\n\n* Redistributions of source code
  must retain the above copyright\n  notice, this list of conditions and the following
  disclaimer.\n\n* Redistributions in binary form must reproduce the above\n  copyright
  notice, this list of conditions and the following\n  disclaimer in the documentation
  and/or other materials provided\n  with the distribution.\n\n* Neither the name
  of  nor the names of other\n  contributors may be used to endorse or promote products
  derived\n  from this software without specific prior written permission.\n\nTHIS
  SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY
  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES
  OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT
  SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL,
  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT
  OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION)
  HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF
  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
license-name: BSD3
